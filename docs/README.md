# ğŸ“š Documentation - Multi-Node Chat Stream Architecture

## Tá»•ng Quan

ÄÃ¢y lÃ  tÃ i liá»‡u Ä‘áº§y Ä‘á»§ vá» kiáº¿n trÃºc Multi-Node Chat Stream vá»›i Kafka integration.

---

## ğŸ“– Documents

### 1. [FIXES_SUMMARY.md](../FIXES_SUMMARY.md)
**TÃ³m táº¯t cÃ¡c váº¥n Ä‘á» Ä‘Ã£ fix**

Issues resolved:
- âœ… UI text replacement â†’ Fixed accumulation logic
- âœ… Kafka not being used â†’ Integrated into architecture

**Äá»c náº¿u**: Báº¡n muá»‘n biáº¿t nhá»¯ng gÃ¬ Ä‘Ã£ Ä‘Æ°á»£c sá»­a vÃ  cÃ¡ch implement.

---

### 2. [KAFKA_MULTI_NODE_ARCHITECTURE.md](./KAFKA_MULTI_NODE_ARCHITECTURE.md)
**Kiáº¿n trÃºc chi tiáº¿t vá» Kafka trong Multi-Node**

Topics covered:
- Event Sourcing & Audit Trail
- Async Background Processing  
- Guaranteed Message Delivery
- Stream Replay & Recovery
- Multi-Node Coordination

**Äá»c náº¿u**: Báº¡n muá»‘n hiá»ƒu sÃ¢u vá» architecture vÃ  design patterns.

**Ná»™i dung**:
- ğŸ“Š Architecture diagrams
- ğŸ’» Implementation examples
- ğŸ”§ Configuration details
- ğŸ¯ Use cases & scenarios
- âš¡ Performance analysis

---

### 3. [KAFKA_USAGE_GUIDE.md](./KAFKA_USAGE_GUIDE.md)
**HÆ°á»›ng dáº«n sá»­ dá»¥ng cÃ¡c tÃ­nh nÄƒng Kafka**

Guides:
- âœ… Quick start
- âœ… Enable/disable Kafka
- âœ… Query audit logs
- âœ… View analytics
- âœ… Replay streams
- âœ… Add custom consumers
- âœ… Monitor & troubleshoot

**Äá»c náº¿u**: Báº¡n muá»‘n thá»±c hÃ nh vÃ  sá»­ dá»¥ng features.

**Practical Examples**:
```java
// Query audit logs
auditLogRepository.findByUserId("user_123");

// Replay session
replayService.replaySession("session_123");

// Add custom consumer
@KafkaListener(topics = "chat-events")
public void processEvent(String event) { ... }
```

---

### 4. [KAFKA_SUMMARY.md](./KAFKA_SUMMARY.md)
**TÃ³m táº¯t toÃ n bá»™ Kafka integration**

Quick reference:
- ğŸ¯ Why Kafka?
- ğŸ—ï¸ Architecture overview
- ğŸ“Š 4 use cases chi tiáº¿t
- ğŸ”„ Message flow
- ğŸ“ˆ Metrics & monitoring
- âš¡ Performance impact
- ğŸ“ Best practices

**Äá»c náº¿u**: Báº¡n muá»‘n overview nhanh vá» toÃ n bá»™ system.

---

## ğŸš€ Quick Start

### 1. Enable Kafka

```bash
# Already enabled in docker-compose.yml
java-websocket:
  environment:
    - KAFKA_ENABLED=true
    - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
```

### 2. Start Services

```bash
docker-compose up -d

# Check logs
docker logs demo-java-websocket | grep "Kafka"

# Expected:
# Kafka EventPublisher enabled for event sourcing and analytics
# AuditTrailConsumer initialized - audit logging enabled
# AnalyticsConsumer initialized - real-time analytics enabled
```

### 3. Send Test Message

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "test_session",
    "user_id": "demo_user",
    "message": "Hello Kafka!"
  }'
```

### 4. View Results

```bash
# 1. Kafka UI
http://localhost:8090
# Topics: chat-events, stream-events

# 2. H2 Console (Audit Logs)
http://localhost:8080/h2-console
# SELECT * FROM audit_logs ORDER BY timestamp DESC;

# 3. Logs (Metrics)
docker logs demo-java-websocket | grep "\[METRIC\]"
```

---

## ğŸ¯ Use Cases

### 1. Event Sourcing & Audit Trail

```java
// Query user activity
List<AuditLog> logs = auditLogRepository.findByUserId("user_123");

// Find errors
List<AuditLog> errors = auditLogRepository.findErrorEvents();

// Conversation history
List<AuditLog> conversation = 
    auditLogRepository.findByConversationId("conv_abc");
```

**Benefits**:
- âœ… Complete audit trail
- âœ… Compliance & regulatory
- âœ… Security auditing
- âœ… Debug production issues

---

### 2. Real-time Analytics

```java
// Metrics are automatically tracked
analytics.sessions.started              // Counter
analytics.streams.completed             // Counter
analytics.stream.duration               // Timer
analytics.stream.words_per_second       // Gauge
analytics.message.length                // Histogram
analytics.errors.stream                 // Counter
```

**Benefits**:
- âœ… Performance monitoring
- âœ… User engagement
- âœ… Error tracking
- âœ… Capacity planning

---

### 3. Stream Replay

```java
// Debug specific session
List<Map<String, Object>> events = 
    replayService.replaySession("session_123");

// Replay from timestamp
replayService.replayFromTimestamp(
    "stream-events",
    Instant.now().minus(Duration.ofHours(1)),
    event -> processEvent(event)
);
```

**Benefits**:
- âœ… Debug production issues
- âœ… Rebuild corrupted data
- âœ… Test with production data
- âœ… Backfill new consumers

---

### 4. Async Processing

```java
// Add custom consumer
@Service
@KafkaListener(topics = "chat-events", groupId = "my-consumer")
public void processEvent(String eventJson) {
    // Your custom logic
    // - Search indexing
    // - ML training data
    # - Email notifications
    // - Analytics aggregation
}
```

**Benefits**:
- âœ… No impact on latency
- âœ… Scale independently
- âœ… Add features easily
- âœ… Parallel processing

---

## ğŸ“Š Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Multi-Node Architecture                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Frontend                                                   â”‚
â”‚     â”‚                                                        â”‚
â”‚     â”‚ WebSocket                                              â”‚
â”‚     â–¼                                                        â”‚
â”‚  Java WebSocket Servers (Multi-Node)                       â”‚
â”‚     â”‚                                                        â”‚
â”‚     â”œâ”€â”€â–¶ Redis PubSub (real-time, < 100ms)                 â”‚
â”‚     â”‚    â””â”€â”€â–¶ WebSocket â†’ Client âœ…                         â”‚
â”‚     â”‚                                                        â”‚
â”‚     â””â”€â”€â–¶ Kafka Topics (async, no latency impact)           â”‚
â”‚          â”‚                                                   â”‚
â”‚          â”œâ”€â”€â–¶ AuditTrailConsumer â†’ Database                â”‚
â”‚          â”œâ”€â”€â–¶ AnalyticsConsumer â†’ Metrics                  â”‚
â”‚          â”œâ”€â”€â–¶ SearchIndexer â†’ Elasticsearch                â”‚
â”‚          â”œâ”€â”€â–¶ MLTrainingData â†’ S3                          â”‚
â”‚          â””â”€â”€â–¶ Notifications â†’ Email/Slack                  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Components Implemented

### Core Services

| Component | Purpose | Status |
|-----------|---------|--------|
| `EventPublisher` | Publish events to Kafka | âœ… Done |
| `ChatOrchestrator` | Integrate Kafka publishing | âœ… Done |
| `RecoveryService` | Track recovery events | âœ… Done |

### Kafka Consumers

| Consumer | Purpose | Status |
|----------|---------|--------|
| `AuditTrailConsumer` | Save events to audit_logs | âœ… Done |
| `AnalyticsConsumer` | Track real-time metrics | âœ… Done |

### Domain Models

| Model | Purpose | Status |
|-------|---------|--------|
| `AuditLog` | Store audit trail | âœ… Done |
| `AuditLogRepository` | Query audit logs | âœ… Done |

### Services

| Service | Purpose | Status |
|---------|---------|--------|
| `StreamReplayService` | Replay historical events | âœ… Done |

---

## ğŸ“ˆ Metrics

### Kafka Metrics

```bash
# Check consumer lag
docker exec demo-kafka kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --describe \
  --group audit-trail-consumer

# View topics
docker exec demo-kafka kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --list
```

### Application Metrics

```bash
# View in logs
docker logs demo-java-websocket | grep "\[METRIC\]"

# Expected output:
[METRIC] analytics.sessions.started: 42
[METRIC] analytics.streams.completed: 40
[METRIC] analytics.stream.duration: avg=2500ms
[METRIC] analytics.chunks.received: 500
```

---

## ğŸ“ Learning Path

### Beginner

1. Read [FIXES_SUMMARY.md](../FIXES_SUMMARY.md) - Hiá»ƒu nhá»¯ng gÃ¬ Ä‘Ã£ fix
2. Read [KAFKA_SUMMARY.md](./KAFKA_SUMMARY.md) - Overview toÃ n bá»™ system
3. Try [Quick Start](#-quick-start) - Thá»­ nghiá»‡m cÆ¡ báº£n

### Intermediate

4. Read [KAFKA_USAGE_GUIDE.md](./KAFKA_USAGE_GUIDE.md) - Há»c cÃ¡ch sá»­ dá»¥ng
5. Query audit logs - Thá»±c hÃ nh vá»›i database
6. Add custom consumer - Táº¡o consumer Ä‘áº§u tiÃªn

### Advanced

7. Read [KAFKA_MULTI_NODE_ARCHITECTURE.md](./KAFKA_MULTI_NODE_ARCHITECTURE.md) - Hiá»ƒu sÃ¢u architecture
8. Implement stream replay - Debug production issues
9. Build analytics dashboard - Visualize metrics

---

## ğŸ› ï¸ Common Tasks

### View Audit Logs

```sql
-- H2 Console: http://localhost:8080/h2-console

-- All events
SELECT * FROM audit_logs ORDER BY timestamp DESC LIMIT 100;

-- Errors only
SELECT * FROM audit_logs WHERE event_type LIKE '%ERROR%';

-- User activity
SELECT event_type, COUNT(*) 
FROM audit_logs 
WHERE user_id = 'demo_user' 
GROUP BY event_type;
```

### Debug Session

```java
@RestController
@RequestMapping("/api/debug")
public class DebugController {
    
    @Autowired
    private StreamReplayService replayService;
    
    @GetMapping("/session/{sessionId}")
    public List<Map<String, Object>> debugSession(@PathVariable String sessionId) {
        return replayService.replaySession(sessionId);
    }
}

// Call: GET http://localhost:8080/api/debug/session/test_session
```

### Monitor Kafka

```bash
# Kafka UI (visual)
http://localhost:8090

# Or CLI
docker exec -it demo-kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic stream-events \
  --from-beginning
```

---

## ğŸ” Troubleshooting

### Kafka not starting

```bash
# Check logs
docker logs demo-kafka

# Common fix: Remove volume and restart
docker-compose down
docker volume rm demo_kafka-data
docker-compose up -d
```

### Events not saved

```bash
# Check Kafka enabled
docker logs demo-java-websocket | grep "KAFKA_ENABLED"

# Should see: KAFKA_ENABLED=true

# Check consumers initialized
docker logs demo-java-websocket | grep "Consumer initialized"

# Should see:
# AuditTrailConsumer initialized
# AnalyticsConsumer initialized
```

### Consumer lag

```bash
# Check lag
docker exec demo-kafka kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --describe \
  --all-groups

# High lag = Consumer slower than producer
# Solution: Increase concurrency or add more consumers
```

---

## ğŸ“š Additional Resources

### Configuration Files

- `docker-compose.yml` - Kafka & services config
- `application.yml` - Spring Boot Kafka settings
- `KafkaConfig.java` - Producer & consumer config

### Key Classes

```
java-websocket-server/src/main/java/com/demo/websocket/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ KafkaConfig.java                 # Kafka configuration
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ EventPublisher.java              # Publish events
â”‚   â””â”€â”€ StreamReplayService.java         # Replay streams
â”œâ”€â”€ consumer/
â”‚   â”œâ”€â”€ AuditTrailConsumer.java          # Audit logging
â”‚   â””â”€â”€ AnalyticsConsumer.java           # Metrics tracking
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ ChatOrchestrator.java            # Integrated publishing
â”‚   â””â”€â”€ RecoveryService.java             # Recovery events
â”œâ”€â”€ domain/
â”‚   â””â”€â”€ AuditLog.java                    # Audit entity
â””â”€â”€ repository/
    â””â”€â”€ AuditLogRepository.java          # Query audit logs
```

---

## ğŸ¯ Summary

**Kafka Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p Ä‘áº§y Ä‘á»§** vÃ o Multi-Node Chat Stream Architecture:

âœ… **Event Sourcing**: Complete audit trail  
âœ… **Analytics**: Real-time metrics  
âœ… **Stream Replay**: Debug & recovery  
âœ… **Async Processing**: No latency impact  
âœ… **Guaranteed Delivery**: At-least-once semantics  
âœ… **Extensibility**: Easy to add consumers  

**Architecture**: Redis (real-time) + Kafka (reliability) = Perfect combo! ğŸš€

---

## ğŸ“ Next Steps

1. âœ… Read documents theo learning path
2. âœ… Start services vÃ  test
3. âœ… Query audit logs
4. âœ… View metrics
5. âœ… Try stream replay
6. âœ… Add custom consumer
7. âœ… Build analytics dashboard

**Happy Coding!** ğŸ‰
