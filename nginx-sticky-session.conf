user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 2048;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging format with upstream info
    log_format upstream_info '$remote_addr - $remote_user [$time_local] '
                           '"$request" $status $body_bytes_sent '
                           '"$http_referer" "$http_user_agent" '
                           'upstream: $upstream_addr '
                           'upstream_status: $upstream_status '
                           'request_time: $request_time '
                           'upstream_response_time: $upstream_response_time';

    access_log /var/log/nginx/access.log upstream_info;

    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript 
               application/json application/javascript application/xml+rss;

    # ==========================================
    # Upstream Configuration with Sticky Sessions
    # ==========================================
    
    # WebSocket upstream with ip_hash for sticky sessions
    upstream websocket_backend {
        # ip_hash ensures same client IP connects to same server
        # This is crucial for WebSocket persistent connections
        ip_hash;
        
        server java-websocket-1:8080 max_fails=3 fail_timeout=30s weight=1;
        server java-websocket-2:8080 max_fails=3 fail_timeout=30s weight=1;
        server java-websocket-3:8080 max_fails=3 fail_timeout=30s weight=1;
        
        # Keepalive connections to upstream
        keepalive 32;
    }

    # AI Service upstream with least_conn for better load distribution
    upstream ai_backend {
        least_conn;
        
        server python-ai-1:8000 max_fails=3 fail_timeout=30s;
        server python-ai-2:8000 max_fails=3 fail_timeout=30s;
        server python-ai-3:8000 max_fails=3 fail_timeout=30s;
    }

    # ==========================================
    # WebSocket Upgrade Mapping
    # ==========================================
    
    map $http_upgrade $connection_upgrade {
        default upgrade;
        '' close;
    }

    # ==========================================
    # Main Server Block
    # ==========================================
    
    server {
        listen 80;
        server_name localhost;

        # Increase buffer sizes for WebSocket
        client_body_buffer_size 128k;
        client_max_body_size 10m;
        large_client_header_buffers 4 32k;

        # ==========================================
        # WebSocket Endpoint
        # ==========================================
        
        location /ws/ {
            proxy_pass http://websocket_backend;

            # WebSocket specific headers
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;

            # Standard proxy headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Forwarded-Port $server_port;

            # Timeouts for long-lived WebSocket connections
            proxy_connect_timeout 7d;
            proxy_send_timeout 7d;
            proxy_read_timeout 7d;

            # Disable buffering for real-time streaming
            proxy_buffering off;
            proxy_cache_bypass $http_upgrade;

            # Enable TCP keepalive
            proxy_socket_keepalive on;
        }

        # ==========================================
        # API Endpoints (REST API to AI Service)
        # ==========================================
        
        location /api/ {
            proxy_pass http://ai_backend/;

            # Standard headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Timeouts for API calls
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;

            # Enable buffering for regular API calls
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
        }

        # ==========================================
        # Health Check Endpoint
        # ==========================================
        
        location /health {
            access_log off;
            
            proxy_pass http://websocket_backend/actuator/health;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            
            proxy_connect_timeout 5s;
            proxy_send_timeout 5s;
            proxy_read_timeout 5s;
        }

        # ==========================================
        # Actuator Endpoints (for monitoring)
        # ==========================================
        
        location /actuator/ {
            proxy_pass http://websocket_backend/actuator/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        # ==========================================
        # Root - Status Page
        # ==========================================
        
        location = / {
            return 200 '{"status":"ok","service":"AI Chat Load Balancer","mode":"sticky-session","upstream":"ip_hash"}\n';
            add_header Content-Type application/json;
        }

        # ==========================================
        # Error Pages
        # ==========================================
        
        error_page 502 503 504 /50x.html;
        location = /50x.html {
            return 503 '{"error":"Service temporarily unavailable","code":503}\n';
            add_header Content-Type application/json;
        }
    }

    # ==========================================
    # Admin/Metrics Server (Internal)
    # ==========================================
    
    server {
        listen 8090;
        server_name localhost;

        # Nginx stub status for monitoring
        location /nginx-status {
            stub_status on;
            access_log off;
        }

        # Health check without upstream dependency
        location /health {
            access_log off;
            return 200 '{"status":"ok","timestamp":"$time_iso8601"}\n';
            add_header Content-Type application/json;
        }

        location / {
            return 404;
        }
    }
}
