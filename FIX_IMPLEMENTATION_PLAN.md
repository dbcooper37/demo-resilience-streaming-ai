# üîß K·∫ø Ho·∫°ch Tri·ªÉn Khai S·ª≠a L·ªói Chunk 7 Data Loss

**M·ª•c ti√™u:** Lo·∫°i b·ªè race condition g√¢y m·∫•t d·ªØ li·ªáu trong WebSocket connection flow

---

## üêõ V·∫•n ƒê·ªÅ Hi·ªán T·∫°i

**File:** `ChatWebSocketHandler.java`  
**Lines:** 99-106

```java
// ‚ùå TH·ª® T·ª∞ SAI
sendChatHistory(wsSession, sessionId);           // Line 100 - ƒê·ªçc history tr∆∞·ªõc
chatOrchestrator.startStreamingSession(...);     // Line 104 - Subscribe sau

// Kho·∫£ng gap gi·ªØa 2 d√≤ng = "Risk Window" (~10-50ms)
// ‚Üí Messages publish trong window n√†y B·ªä M·∫§T vƒ©nh vi·ªÖn!
```

**H·∫≠u qu·∫£:**
- 1-10% connections b·ªã m·∫•t chunks
- Client nh·∫≠n: `[1,2,3,4,5,6,‚ùå7,8,9,10...]`
- Kh√¥ng th·ªÉ recovery

---

## ‚úÖ Gi·∫£i Ph√°p

### 1Ô∏è‚É£ Backend: ƒê·∫£o Ng∆∞·ª£c Th·ª© T·ª± (30 ph√∫t)

**File:** `java-websocket-server/src/main/java/com/demo/websocket/handler/ChatWebSocketHandler.java`

```java
@Override
public void afterConnectionEstablished(WebSocketSession wsSession) throws Exception {
    String sessionId = extractSessionId(wsSession);
    String userId = extractUserId(wsSession);
    String token = extractToken(wsSession);

    // Validation
    if (!securityValidator.validateToken(token, userId)) {
        wsSession.close(CloseStatus.NOT_ACCEPTABLE);
        return;
    }

    // Register session
    sessionManager.registerSession(sessionId, wsSession, userId);
    
    // ‚úÖ B∆Ø·ªöC 1: Subscribe to PubSub TR∆Ø·ªöC (line 104 ‚Üí line 100)
    chatOrchestrator.startStreamingSession(sessionId, userId,
            new WebSocketStreamCallback(wsSession));
    
    // ‚úÖ B∆Ø·ªöC 2: Send history SAU (line 100 ‚Üí line 104)  
    sendChatHistory(wsSession, sessionId);
    
    // ‚úÖ B∆Ø·ªöC 3: Welcome message
    sendWelcomeMessage(wsSession, sessionId);
    
    // Record metrics
    metricsService.recordWebSocketConnection(userId, true);
}
```

**T·∫°i sao ho·∫°t ƒë·ªông:**
- Subscribe tr∆∞·ªõc ‚Üí nh·∫≠n T·∫§T C·∫¢ messages m·ªõi (7, 8, 9...)
- Read history sau ‚Üí nh·∫≠n messages c≈© (1-6, c√≥ th·ªÉ c·∫£ 7)
- C√≥ duplicate ‚Üí client x·ª≠ l√Ω deduplication
- **Zero data loss!** ‚úÖ

---

### 2Ô∏è‚É£ Frontend: Th√™m Deduplication (1 gi·ªù)

**File:** `frontend/src/hooks/useChat.js`

```javascript
export const useChat = (sessionId) => {
  const [messages, setMessages] = useState([]);
  const seenChunksRef = useRef(new Set());

  const handleWebSocketMessage = useCallback((data) => {
    if (data.type !== 'message') return;
    
    const msg = data.data;
    const chunkKey = `${msg.messageId}-${msg.chunkIndex || 0}`;
    
    // ‚úÖ Deduplication: Skip if already seen
    if (seenChunksRef.current.has(chunkKey)) {
      console.log('Duplicate chunk skipped:', chunkKey);
      return;
    }
    
    seenChunksRef.current.add(chunkKey);
    
    // Process message
    setMessages(prev => {
      const existingIdx = prev.findIndex(m => m.messageId === msg.messageId);
      
      if (existingIdx >= 0) {
        // Update existing message
        const updated = [...prev];
        updated[existingIdx] = {
          ...updated[existingIdx],
          content: msg.content,
          isComplete: msg.isComplete
        };
        return updated;
      } else {
        // New message
        return [...prev, msg];
      }
    });
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      seenChunksRef.current.clear();
    };
  }, []);

  return { messages, handleWebSocketMessage };
};
```

**L∆∞u √Ω:**
- D√πng `Set` ƒë·ªÉ track `(messageId, chunkIndex)` ƒë√£ th·∫•y
- Skip duplicates m·ªôt c√°ch silent
- Clear khi component unmount

---

### 3Ô∏è‚É£ Testing (2 gi·ªù)

#### Test Case 1: Normal Flow
```
‚úÖ Client connect ‚Üí Subscribe ‚Üí Read history ‚Üí Receive new messages
‚úÖ No data loss
‚úÖ Duplicates handled correctly
```

#### Test Case 2: High Frequency Streaming
```
‚úÖ AI streaming nhanh (10 chunks/sec)
‚úÖ Client v·∫´n nh·∫≠n ƒë·∫ßy ƒë·ªß chunks
‚úÖ No missing data
```

#### Test Case 3: Multiple Concurrent Connections
```
‚úÖ 100 clients connect ƒë·ªìng th·ªùi
‚úÖ T·∫•t c·∫£ ƒë·ªÅu nh·∫≠n ƒë·∫ßy ƒë·ªß data
‚úÖ No race condition
```

#### Test Case 4: Network Interruption
```
‚úÖ Client disconnect gi·ªØa ch·ª´ng
‚úÖ Reconnect v√† resume
‚úÖ No duplicate processing
```

---

## üìã Implementation Checklist

### Phase 1: Backend Fix (30 ph√∫t)

- [ ] Backup file `ChatWebSocketHandler.java`
- [ ] Swap lines 100 v√† 104
- [ ] Th√™m comment gi·∫£i th√≠ch th·ª© t·ª±
- [ ] Local test v·ªõi single client
- [ ] Commit: "fix: resolve chunk 7 data loss race condition"

### Phase 2: Frontend Deduplication (1 gi·ªù)

- [ ] Update `useChat.js` v·ªõi deduplication logic
- [ ] Th√™m debug logging cho duplicates
- [ ] Test v·ªõi manually injected duplicates
- [ ] Commit: "feat: add message deduplication in client"

### Phase 3: Testing (2 gi·ªù)

- [ ] Unit tests cho backend fix
- [ ] Integration tests cho full flow
- [ ] Load test v·ªõi 100+ concurrent users
- [ ] Verify no regression
- [ ] Update test documentation

### Phase 4: Deployment

- [ ] Deploy to staging environment
- [ ] Monitor metrics for 24h
- [ ] Check logs for any duplicates
- [ ] Deploy to production
- [ ] Monitor for 1 week

---

## üîç Monitoring

### Metrics to Track

1. **Data Loss Rate** (should be 0%)
   ```java
   // Log when PUBLISH returns 0 subscribers
   logger.warn("No subscribers for session {}", sessionId);
   metricsService.recordDataLoss(sessionId);
   ```

2. **Duplicate Rate** (expected: 1-5%)
   ```javascript
   // Log duplicates in frontend
   console.log('Duplicate rate:', duplicates / total);
   ```

3. **Connection Success Rate** (should be 99%+)
   ```java
   metricsService.recordConnectionSuccess(userId);
   ```

### Alerts

- ‚ö†Ô∏è Data loss rate > 0% ‚Üí Critical alert
- ‚ö†Ô∏è Duplicate rate > 10% ‚Üí Warning
- ‚ö†Ô∏è Connection success < 95% ‚Üí Warning

---

## üéØ Expected Results

### Before Fix

| Metric | Value |
|--------|-------|
| Data Loss | 1-10% |
| User Impact | High |
| Conversations | Broken |

### After Fix

| Metric | Value |
|--------|-------|
| Data Loss | 0% ‚úÖ |
| User Impact | None |
| Conversations | Perfect ‚úÖ |
| Duplicate Rate | 1-5% (handled) |

---

## üîÑ Rollback Plan

N·∫øu c√≥ issue sau khi deploy:

1. **Revert commit** trong Git
2. **Redeploy** version c≈©
3. **Investigate** logs ƒë·ªÉ t√¨m root cause
4. **Fix** v√† test l·∫°i
5. **Redeploy** version m·ªõi

```bash
# Rollback command
git revert <commit-hash>
git push origin main

# Redeploy
./deploy.sh
```

---

## üìö Documentation Updates

- [ ] Update `DOCUMENTATION.md` v·ªõi fix explanation
- [ ] Update `DOCUMENTATION_VI.md`
- [ ] Add section v·ªÅ deduplication strategy
- [ ] Update architecture diagrams n·∫øu c·∫ßn

---

## üí° Future Improvements

### Option 1: Migrate to Redis Streams (Long-term)

**Pros:**
- Messages ƒë∆∞·ª£c persist
- Built-in catch-up mechanism
- No race condition possible

**Cons:**
- Major code changes
- Migration complexity
- Higher memory usage

**Timeline:** 2-4 weeks

### Option 2: Add Sequence Numbers

**Pros:**
- Detect gaps automatically
- Self-healing
- Better debugging

**Cons:**
- Additional complexity
- Need gap-filling API

**Timeline:** 1 week

---

## ‚úÖ Sign-off

### Developer
- [ ] Code changes complete
- [ ] Self-tested locally
- [ ] PR submitted

### Code Review
- [ ] Logic verified
- [ ] No regression
- [ ] Approved

### QA
- [ ] Test cases passed
- [ ] Load test passed
- [ ] Ready for deployment

### DevOps
- [ ] Deployed to staging
- [ ] Monitored 24h
- [ ] Deployed to production

---

**Timeline Total:** ~4 gi·ªù implementation + 1 ng√†y monitoring  
**Risk Level:** LOW (simple code swap, fully tested)  
**Impact:** HIGH (eliminates critical data loss bug)

**Status:** ‚úÖ Ready for implementation
