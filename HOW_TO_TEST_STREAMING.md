# HÆ°á»›ng dáº«n Test Streaming - Step by Step

## ğŸ¯ Má»¥c tiÃªu
Sau khi apply táº¥t cáº£ fixes, streaming pháº£i hoáº¡t Ä‘á»™ng:
- User gá»­i message â†’ AI response streaming tá»«ng tá»« má»™t
- Frontend hiá»ƒn thá»‹ streaming indicator (3 dots)
- Má»—i chunk update accumulated text
- Complete message xuáº¥t hiá»‡n cuá»‘i cÃ¹ng

## ğŸ“‹ CÃ¡c sá»­a Ä‘á»•i Ä‘Ã£ thá»±c hiá»‡n

### Java WebSocket Server
1. âœ… Disable duplicate subscription (chá»‰ dÃ¹ng ChatOrchestrator)
2. âœ… Convert StreamChunk â†’ ChatMessage format
3. âœ… Use accumulated content thay vÃ¬ chá»‰ chunk
4. âœ… Enhanced logging

### Python AI Service  
1. âœ… TÄƒng delays (0.3s giá»¯a words, 0.1s sau publish)
2. âœ… ThÃªm logging chi tiáº¿t
3. âœ… Track subscribers count

### Files Ä‘Ã£ sá»­a
- `ChatWebSocketHandler.java`
- `ChatOrchestrator.java`
- `RedisMessageListener.java`
- `config.py`
- `ai_service.py`
- `redis_client.py`

## ğŸš€ CÃ¡ch test

### BÆ°á»›c 1: Rebuild vÃ  khá»Ÿi Ä‘á»™ng services

```bash
cd /workspace

# Stop táº¥t cáº£ services
docker compose down

# Rebuild vÃ  start láº¡i
docker compose up --build -d

# Äá»£i services khá»Ÿi Ä‘á»™ng (khoáº£ng 10-20 giÃ¢y)
docker compose ps
```

Kiá»ƒm tra táº¥t cáº£ services Ä‘ang cháº¡y:
```
NAME                    STATUS
frontend                Up
java-websocket-server   Up
postgres                Up
python-ai-service       Up
redis                   Up
```

### BÆ°á»›c 2: Má»Ÿ terminal logs (Terminal riÃªng)

Má»Ÿ 2 terminal Ä‘á»ƒ xem logs real-time:

**Terminal 1 - Python logs:**
```bash
docker compose logs -f python-ai-service | grep -E "(Starting|Published|Completed|subscribers)"
```

**Terminal 2 - Java logs:**
```bash
docker compose logs -f java-websocket-server | grep -E "(ChatOrchestrator|sendChunk|Broadcasting|Calling callback)"
```

### BÆ°á»›c 3: Má»Ÿ frontend vÃ  test

1. Má»Ÿ browser: http://localhost:3000
2. Kiá»ƒm tra WebSocket connection:
   - Má»Ÿ DevTools (F12)
   - Tab Network â†’ Filter "WS"
   - Sáº½ tháº¥y connection Ä‘áº¿n `ws://localhost:8080/ws/chat`
   - Status: "101 Switching Protocols" (connected)

3. Gá»­i má»™t message, vÃ­ dá»¥: "xin chÃ o"

### BÆ°á»›c 4: Quan sÃ¡t káº¿t quáº£

#### A. TrÃªn Frontend (Browser)

**Ngay láº­p tá»©c:**
- User message "xin chÃ o" xuáº¥t hiá»‡n

**Sau ~1 giÃ¢y:**
- AI response báº¯t Ä‘áº§u xuáº¥t hiá»‡n
- Tháº¥y streaming indicator (3 dots animation)
- Text xuáº¥t hiá»‡n tá»«ng tá»« má»™t:
  - "Xin "
  - "Xin chÃ o! "
  - "Xin chÃ o! TÃ´i "
  - "Xin chÃ o! TÃ´i lÃ  "
  - ... (tiáº¿p tá»¥c)

**Cuá»‘i cÃ¹ng:**
- Complete message hiá»ƒn thá»‹ Ä‘áº§y Ä‘á»§
- Streaming indicator biáº¿n máº¥t (no dots)

#### B. Trong Python logs (Terminal 1)

Báº¡n sáº½ tháº¥y:
```
Starting AI response streaming for session=session_xxx, msg_id=yyy
Selected response text (length=78): Xin chÃ o! TÃ´i lÃ  AI assistant. TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ ch...
Published to chat:stream:session_xxx: role=assistant, is_complete=False, content_len=4, subscribers=1
Published to chat:stream:session_xxx: role=assistant, is_complete=False, content_len=10, subscribers=1
Published to chat:stream:session_xxx: role=assistant, is_complete=False, content_len=14, subscribers=1
...
Published to chat:stream:session_xxx: role=assistant, is_complete=True, content_len=78, subscribers=1
Completed AI response streaming: session=session_xxx, msg_id=yyy, chunks=15, total_length=78
```

**Quan trá»ng**: Kiá»ƒm tra `subscribers=1` (hoáº·c hÆ¡n). Náº¿u `subscribers=0` â†’ cÃ³ váº¥n Ä‘á»!

#### C. Trong Java logs (Terminal 2)

Báº¡n sáº½ tháº¥y:
```
ChatOrchestrator received message from chat:stream:session_xxx: {"message_id":"yyy",...}
Handling legacy message for session session_xxx: role=assistant, isComplete=false, contentLength=4
Calling callback.onChunk for messageId: yyy, index: 0
Sending chunk to WebSocket session xxx: index=0, contentLength=4
...
Handling legacy message for session session_xxx: role=assistant, isComplete=true, contentLength=78
Sending chunk to WebSocket session xxx: index=14, contentLength=78
```

#### D. Trong Browser DevTools

**Console tab**: KhÃ´ng cÃ³ errors

**Network â†’ WS tab**: Click vÃ o WebSocket connection â†’ Messages
Báº¡n sáº½ tháº¥y messages:
```json
{"type":"welcome","sessionId":"session_xxx","timestamp":"..."}
{"type":"message","data":{"message_id":"yyy","role":"assistant","content":"Xin ","is_complete":false,...}}
{"type":"message","data":{"message_id":"yyy","role":"assistant","content":"Xin chÃ o! ","is_complete":false,...}}
...
{"type":"message","data":{"message_id":"yyy","role":"assistant","content":"Xin chÃ o! TÃ´i lÃ  AI assistant...","is_complete":true,...}}
```

## âœ… Checklist - Streaming hoáº¡t Ä‘á»™ng Ä‘Ãºng

ÄÃ¡nh dáº¥u vÃ o cÃ¡c má»¥c sau:

### Python Service
- [ ] Log "Starting AI response streaming" xuáº¥t hiá»‡n
- [ ] Log "Published to chat:stream" cho má»—i chunk
- [ ] **subscribers=1 hoáº·c hÆ¡n** (khÃ´ng pháº£i 0!)
- [ ] Log "Completed AI response streaming" vá»›i sá»‘ chunks Ä‘Ãºng
- [ ] KhÃ´ng cÃ³ error logs

### Java Service
- [ ] Log "ChatOrchestrator received message" xuáº¥t hiá»‡n
- [ ] Log "Handling legacy message" cho má»—i chunk
- [ ] Log "Calling callback.onChunk"
- [ ] Log "Sending chunk to WebSocket"
- [ ] KhÃ´ng cÃ³ error logs

### Frontend
- [ ] WebSocket status = "connected" (xanh)
- [ ] User message xuáº¥t hiá»‡n ngay
- [ ] AI response streaming tá»«ng tá»« má»™t
- [ ] Streaming indicator (3 dots) hiá»ƒn thá»‹
- [ ] Complete message cuá»‘i cÃ¹ng (no indicator)
- [ ] KhÃ´ng cÃ³ console errors

### Browser DevTools
- [ ] WebSocket connection status 101
- [ ] Nháº­n Ä‘Æ°á»£c messages type="message"
- [ ] Message data cÃ³ Ä‘Ãºng format ChatMessage
- [ ] is_complete=false cho streaming chunks
- [ ] is_complete=true cho final message

## âŒ Troubleshooting

### Váº¥n Ä‘á» 1: subscribers=0 trong Python logs

**NghÄ©a lÃ **: Java server khÃ´ng subscribe Redis channel

**Kiá»ƒm tra**:
```bash
docker compose logs java-websocket-server | grep "Subscribed to legacy channel"
```

Pháº£i tháº¥y: `Subscribed to legacy channel: chat:stream:xxx with listener`

**Náº¿u khÃ´ng tháº¥y**:
- WebSocket chÆ°a connect â†’ Check frontend connection
- `ChatOrchestrator.startStreamingSession()` khÃ´ng Ä‘Æ°á»£c gá»i â†’ Check Java logs khi WebSocket connect

### Váº¥n Ä‘á» 2: Python publish nhÆ°ng Java khÃ´ng receive

**Kiá»ƒm tra Redis**:
```bash
# Test Redis PubSub trá»±c tiáº¿p
python3 /workspace/test_redis_pubsub.py
```

**Hoáº·c manual test**:
```bash
# Terminal 1
docker compose exec redis redis-cli
> SUBSCRIBE chat:stream:test_session

# Terminal 2
docker compose exec redis redis-cli
> PUBLISH chat:stream:test_session "test message"

# Terminal 1 pháº£i nháº­n Ä‘Æ°á»£c message
```

### Váº¥n Ä‘á» 3: Java receive nhÆ°ng khÃ´ng send qua WebSocket

**Kiá»ƒm tra**:
```bash
docker compose logs java-websocket-server | grep -E "(WebSocket session.*is not open|Failed to send)"
```

CÃ³ thá»ƒ WebSocket Ä‘Ã£ disconnect. Refresh browser vÃ  thá»­ láº¡i.

### Váº¥n Ä‘á» 4: Frontend khÃ´ng hiá»ƒn thá»‹ streaming

**Kiá»ƒm tra Browser DevTools**:
- Network â†’ WS â†’ Messages: CÃ³ nháº­n Ä‘Æ°á»£c messages khÃ´ng?
- Console: CÃ³ errors khÃ´ng?

**Kiá»ƒm tra code**:
```javascript
// useChat.js pháº£i handle cáº£ streaming vÃ  complete messages
if (message.is_complete) {
  // Final message
} else {
  // Streaming chunk
}
```

### Váº¥n Ä‘á» 5: Streaming quÃ¡ nhanh/cháº­m

**Adjust delays trong environment**:
```bash
# Táº¡o file .env hoáº·c edit docker-compose.yml
STREAM_DELAY=0.5  # Cháº­m hÆ¡n, dá»… tháº¥y
CHUNK_DELAY=0.2

# Hoáº·c nhanh hÆ¡n
STREAM_DELAY=0.1
CHUNK_DELAY=0.05
```

Rebuild sau khi thay Ä‘á»•i:
```bash
docker compose down
docker compose up --build -d
```

## ğŸ”§ Advanced Testing

### Test vá»›i nhiá»u messages liÃªn tiáº¿p

Gá»­i nhiá»u messages nhanh Ä‘á»ƒ test:
1. "hello"
2. "how are you"  
3. "tell me about redis"

Má»—i message pháº£i streaming riÃªng biá»‡t, khÃ´ng bá»‹ overlap.

### Test vá»›i long message

Gá»­i message dÃ i Ä‘á»ƒ tháº¥y rÃµ streaming:
```
"HÃ£y giáº£i thÃ­ch chi tiáº¿t vá» kiáº¿n trÃºc cá»§a há»‡ thá»‘ng chat streaming nÃ y"
```

### Test reconnection

1. Gá»­i message vÃ  Ä‘á»£i streaming
2. Táº¯t WiFi giá»¯a chá»«ng
3. Báº­t láº¡i WiFi
4. Kiá»ƒm tra recovery

### Load test

Sá»­ dá»¥ng curl Ä‘á»ƒ test:
```bash
for i in {1..10}; do
  curl -X POST http://localhost:8000/chat \
    -H "Content-Type: application/json" \
    -d "{\"session_id\":\"test_$i\",\"user_id\":\"user_$i\",\"message\":\"test $i\"}" &
done
wait
```

## ğŸ“Š Performance Metrics

Vá»›i default settings (STREAM_DELAY=0.3s):
- Message ~15 words â‰ˆ 4-5 giÃ¢y streaming
- Message ~30 words â‰ˆ 9-10 giÃ¢y streaming

Vá»›i production settings (STREAM_DELAY=0.1s):
- Message ~15 words â‰ˆ 1.5-2 giÃ¢y streaming
- Message ~30 words â‰ˆ 3-4 giÃ¢y streaming

## ğŸ“ Summary

Táº¥t cáº£ pháº£i hoáº¡t Ä‘á»™ng theo flow:

```
User sends message
    â†“
Frontend â†’ POST /api/chat â†’ Python AI Service
    â†“
Python streaming response
    â†“
Publish tá»«ng chunk lÃªn Redis (chat:stream:{session_id})
    â†“
Java ChatOrchestrator receive messages
    â†“
Convert StreamChunk â†’ ChatMessage
    â†“
Send qua WebSocket
    â†“
Frontend receive vÃ  display streaming
    â†“
Complete! âœ…
```

Náº¿u báº¥t ká»³ bÆ°á»›c nÃ o fail, check logs Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ chÃ­nh xÃ¡c.

## ğŸ‰ Success Criteria

Khi streaming hoáº¡t Ä‘á»™ng Ä‘Ãºng:
1. âœ… User message xuáº¥t hiá»‡n ngay láº­p tá»©c
2. âœ… AI response streaming tá»«ng tá»« má»™t vá»›i delay ~0.3s
3. âœ… Streaming indicator hiá»ƒn thá»‹ vÃ  biáº¿n máº¥t Ä‘Ãºng lÃºc
4. âœ… Logs Ä‘áº§y Ä‘á»§ á»Ÿ cáº£ Python vÃ  Java
5. âœ… subscribers >= 1 trong Python logs
6. âœ… KhÃ´ng cÃ³ errors trong báº¥t ká»³ logs nÃ o

Náº¿u táº¥t cáº£ cÃ¡c Ä‘iá»u trÃªn Ä‘á»u OK â†’ Streaming Ä‘Ã£ hoáº¡t Ä‘á»™ng hoÃ n háº£o! ğŸŠ
