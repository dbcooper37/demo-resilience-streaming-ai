# üèóÔ∏è T√†i Li·ªáu Ki·∫øn Tr√∫c K·ªπ Thu·∫≠t: H·ªá Th·ªëng Real-time AI Chat v·ªõi WebSocket v√† Event Sourcing

## üìã T·ªïng Quan

ƒê√¢y l√† t√†i li·ªáu ki·∫øn tr√∫c k·ªπ thu·∫≠t chi ti·∫øt cho h·ªá th·ªëng **Real-time AI Streaming Chat** - m·ªôt ki·∫øn tr√∫c ph√¢n t√°n (distributed architecture) s·ª≠ d·ª•ng WebSocket, Redis PubSub, Apache Kafka v√† Spring Boot ƒë·ªÉ x√¢y d·ª±ng h·ªá th·ªëng chat AI v·ªõi kh·∫£ nƒÉng streaming real-time, l∆∞u tr·ªØ l·ªãch s·ª≠ b·ªÅn v·ªØng (persistent history) v√† ph·ª•c h·ªìi session khi ng∆∞·ªùi d√πng reload trang.

### üéØ V·∫•n ƒê·ªÅ Gi·∫£i Quy·∫øt

**User ƒëang nh·∫≠n streaming response t·ª´ AI, nh∆∞ng khi reload trang, l√†m sao ƒë·ªÉ:**
- ‚úÖ Xem ƒë∆∞·ª£c to√†n b·ªô l·ªãch s·ª≠ chat c≈©
- ‚úÖ Ti·∫øp t·ª•c nh·∫≠n streaming m·ªõi (n·∫øu AI v·∫´n ƒëang tr·∫£ l·ªùi)
- ‚úÖ Kh√¥ng m·∫•t d·ªØ li·ªáu
- ‚úÖ Tr·∫£i nghi·ªám seamless nh∆∞ ch∆∞a h·ªÅ reload

### üîë Gi·∫£i Ph√°p Ch√≠nh

1. **Redis PubSub**: Real-time streaming v·ªõi latency < 100ms
2. **Distributed Session Ownership**: Multi-node coordination kh√¥ng c·∫ßn sticky session
3. **Event Sourcing v·ªõi Kafka**: Audit trail v√† analytics
4. **WebSocket + Auto-Reconnection**: K·∫øt n·ªëi b·ªÅn v·ªØng
5. **Hierarchical Caching**: L1 (Local) + L2 (Redis) cho performance

---

## üé® Ki·∫øn Tr√∫c T·ªïng Quan

```mermaid
graph TB
    subgraph "Client Layer"
        Browser[React Frontend<br/>WebSocket Client]
    end
    
    subgraph "Load Balancer Layer"
        NGINX[NGINX Load Balancer<br/>Round-Robin]
    end
    
    subgraph "Backend Layer - Java WebSocket Servers"
        WS1[Java WS Node 1<br/>:8081]
        WS2[Java WS Node 2<br/>:8082]
        WS3[Java WS Node 3<br/>:8083]
    end
    
    subgraph "AI Service Layer - Python AI Services"
        AI1[Python AI Node 1<br/>:8001]
        AI2[Python AI Node 2<br/>:8002]
        AI3[Python AI Node 3<br/>:8003]
    end
    
    subgraph "Infrastructure Layer"
        Redis[(Redis<br/>PubSub + Storage)]
        Kafka[(Kafka<br/>Event Sourcing)]
        H2[(H2 Database<br/>Messages + Audit)]
    end
    
    Browser -->|WebSocket| NGINX
    Browser -->|REST API| NGINX
    
    NGINX -->|Round-Robin| WS1
    NGINX -->|Round-Robin| WS2
    NGINX -->|Round-Robin| WS3
    
    WS1 -->|Load Balanced| AI1
    WS1 -->|Load Balanced| AI2
    WS1 -->|Load Balanced| AI3
    
    WS2 -->|Load Balanced| AI1
    WS2 -->|Load Balanced| AI2
    WS2 -->|Load Balanced| AI3
    
    WS3 -->|Load Balanced| AI1
    WS3 -->|Load Balanced| AI2
    WS3 -->|Load Balanced| AI3
    
    WS1 -->|PubSub + Lock| Redis
    WS2 -->|PubSub + Lock| Redis
    WS3 -->|PubSub + Lock| Redis
    
    AI1 -->|Publish Chunks| Redis
    AI2 -->|Publish Chunks| Redis
    AI3 -->|Publish Chunks| Redis
    
    WS1 -->|Events| Kafka
    WS2 -->|Events| Kafka
    WS3 -->|Events| Kafka
    
    WS1 -->|Persist| H2
    WS2 -->|Persist| H2
    WS3 -->|Persist| H2
    
    style Browser fill:#e1f5ff
    style NGINX fill:#fff9c4
    style WS1 fill:#c8e6c9
    style WS2 fill:#c8e6c9
    style WS3 fill:#c8e6c9
    style AI1 fill:#f8bbd0
    style AI2 fill:#f8bbd0
    style AI3 fill:#f8bbd0
    style Redis fill:#ffccbc
    style Kafka fill:#d1c4e9
    style H2 fill:#b2dfdb
```

**ƒê·∫∑c ƒëi·ªÉm quan tr·ªçng:**
- ‚ùå **KH√îNG c√≥ sticky session** - NGINX d√πng round-robin thu·∫ßn t√∫y
- ‚úÖ **Distributed session ownership** - Nodes claim session ownership qua Redis SETNX
- ‚úÖ **Stateless services** - T·∫•t c·∫£ state trong Redis (shared)
- ‚úÖ **Horizontal scaling** - Th√™m node m·ªõi kh√¥ng c·∫ßn config g√¨ th√™m

---

## üîÑ Flow Chi Ti·∫øt

### 1. Normal Streaming Flow

```mermaid
sequenceDiagram
    participant Client as Browser
    participant NGINX as NGINX LB
    participant Java as Java WS Node
    participant Python as Python AI Service
    participant Redis as Redis
    participant Kafka as Kafka

    Note over Client,Kafka: User g·ª≠i message "Hello"
    
    Client->>NGINX: POST /api/chat<br/>{session_id, message, user_id}
    NGINX->>Java: Forward request (round-robin)
    
    Note over Java: Check session ownership
    Java->>Redis: SETNX session:owner:{session_id}
    Redis-->>Java: OK (claimed ownership)
    
    Java->>Python: POST /chat (load balanced)
    
    Note over Python: Generate AI response
    Python->>Redis: LPUSH chat:history:{session_id}<br/>(save user message)
    
    loop For each word in response
        Python->>Python: Generate next word
        Python->>Redis: PUBLISH chat:stream:{session_id}<br/>{content: accumulated, chunk: word}
        
        Note over Redis,Java: PubSub fanout
        Redis-->>Java: Message delivered
        
        Java->>Java: Convert to StreamChunk
        Java->>Redis: Cache chunk (L2)
        Java->>Kafka: Publish event (async)
        Java->>Client: Send via WebSocket
        
        Note over Client: Display streaming text
    end
    
    Python->>Redis: PUBLISH chat:stream:{session_id}<br/>{content: final, is_complete: true}
    Redis-->>Java: Final message
    
    Java->>H2: Save complete message
    Java->>Redis: LPUSH chat:history:{session_id}
    Java->>Kafka: STREAM_COMPLETED event
    Java->>Client: Final message via WebSocket
    
    Java->>Redis: DEL session:owner:{session_id}
    Note over Java: Release ownership
```

**Ph√¢n T√≠ch Th·ªùi Gian:**
- B∆∞·ªõc 1-3: ~10-20ms (HTTP + y√™u c·∫ßu ownership)
- B∆∞·ªõc 4-5: ~5-10ms (G·ªçi Python + l∆∞u l·ªãch s·ª≠)
- V√≤ng l·∫∑p: ~2-5 gi√¢y (50ms m·ªói t·ª´)
- K·∫øt th√∫c: ~20-30ms (l∆∞u + d·ªçn d·∫πp)
- **T·ªïng c·ªông**: 2-5 gi√¢y end-to-end

---

### 2. Reload During Streaming Flow

```mermaid
sequenceDiagram
    participant Client as Browser (Old)
    participant Client2 as Browser (New)
    participant NGINX as NGINX LB
    participant Java as Java WS Node
    participant Python as Python AI
    participant Redis as Redis

    Note over Client,Redis: Streaming in progress...
    
    Python->>Redis: PUBLISH chunk #1 "Hello"
    Redis-->>Java: Deliver
    Java->>Client: WebSocket send
    
    Python->>Redis: PUBLISH chunk #2 "world"
    Redis-->>Java: Deliver
    Java->>Client: WebSocket send
    
    Note over Client: ‚ö†Ô∏è USER RELOAD PAGE
    Client->>NGINX: WebSocket disconnect
    NGINX->>Java: Connection closed
    
    Note over Python: ‚ö†Ô∏è AI continues streaming<br/>(doesn't know about disconnect)
    
    Python->>Redis: PUBLISH chunk #3 "this"
    Note over Redis: Saved to history<br/>(but no WebSocket to deliver)
    
    Python->>Redis: PUBLISH chunk #4 "is"
    Python->>Redis: PUBLISH chunk #5 "streaming"
    
    Note over Client2: ‚ïê‚ïê‚ïê PAGE RELOADED ‚ïê‚ïê‚ïê
    
    Client2->>NGINX: New WebSocket connection<br/>ws://...?session_id={same}
    NGINX->>Java: Route to available node (round-robin)
    
    Note over Java: Check session ownership
    Java->>Redis: GET session:owner:{session_id}
    Redis-->>Java: node-2 (owned by another node)
    
    Note over Java: ‚ö†Ô∏è Already owned, don't claim
    
    Java->>Client2: Welcome message
    
    Java->>Redis: LRANGE chat:history:{session_id}
    Redis-->>Java: [user msg, partial assistant msg]
    
    Note over Java: History includes chunks 1-5<br/>even though we didn't deliver them
    
    Java->>Client2: History with partial message<br/>"Hello world this is streaming"
    
    Note over Client2: User sees history immediately!
    
    Note over Java: Subscribe to PubSub for new chunks
    Java->>Redis: SUBSCRIBE chat:stream:{session_id}
    
    Python->>Redis: PUBLISH chunk #6 "!"
    Redis-->>Java: Deliver to subscriber
    Java->>Client2: WebSocket send chunk #6
    
    Python->>Redis: PUBLISH final (is_complete: true)
    Redis-->>Java: Final message
    Java->>Client2: Final message
    
    Note over Client2: ‚úÖ Seamless experience!<br/>Saw history + continued streaming
```

**ƒêi·ªÉm Quan Tr·ªçng:**
- ‚ùå AI service **kh√¥ng bi·∫øt** client ng·∫Øt k·∫øt n·ªëi
- ‚úÖ Chunks v·∫´n ƒë∆∞·ª£c **l∆∞u v√†o Redis history**
- ‚úÖ K·∫øt n·ªëi l·∫°i t·∫£i **to√†n b·ªô l·ªãch s·ª≠** (bao g·ªìm c·∫£ ph·∫ßn ch∆∞a ho√†n th√†nh)
- ‚úÖ Subscribe l·∫°i v√† **ti·∫øp t·ª•c nh·∫≠n chunks m·ªõi**
- ‚úÖ **Kh√¥ng m·∫•t d·ªØ li·ªáu**

---

### 3. Distributed Session Ownership Flow

```mermaid
sequenceDiagram
    participant Client1 as Client A
    participant Client2 as Client B
    participant Java1 as Java Node 1
    participant Java2 as Java Node 2
    participant Redis as Redis

    Note over Client1,Redis: Scenario: 2 clients c√πng session_id
    
    Client1->>Java1: Connect session_123
    
    Note over Java1: Try claim ownership
    Java1->>Redis: SETNX session:owner:123 "node-1"
    Redis-->>Java1: OK (success)
    
    Note over Java1: ‚úÖ Claimed ownership
    Java1->>Redis: SUBSCRIBE chat:stream:123
    
    Note over Client2: A few seconds later...
    Client2->>Java2: Connect session_123
    
    Note over Java2: Try claim ownership
    Java2->>Redis: SETNX session:owner:123 "node-2"
    Redis-->>Java2: FAIL (key exists)
    
    Note over Java2: ‚ö†Ô∏è Already owned by node-1<br/>Don't subscribe (avoid duplicate processing)
    
    Java2->>Client2: Return history only<br/>(passive mode)
    
    Note over Java1,Java2: Only Node 1 processes this session
    
    rect rgb(200, 230, 201)
        Note over Java1: Active processing
        Python->>Redis: PUBLISH chunks
        Redis-->>Java1: Deliver (subscribed)
        Java1->>Client1: Forward to client
    end
    
    rect rgb(255, 224, 130)
        Note over Java2: Passive mode
        Redis->>Java2: (not subscribed)
        Note over Java2: Does nothing
    end
    
    Note over Client1: Stream completed
    Java1->>Redis: DEL session:owner:123
    Note over Java1: Release ownership
    
    Note over Java2: Now can claim if needed
```

**T·∫°i Sao Thi·∫øt K·∫ø N√†y?**

1. **V·∫•n ƒê·ªÅ**: Nhi·ªÅu Java nodes nh·∫≠n k·∫øt n·ªëi t·ª´ c√πng m·ªôt session
2. **Kh√¥ng c√≥ ownership**: X·ª≠ l√Ω tr√πng l·∫∑p, g·ª≠i WebSocket tr√πng l·∫∑p
3. **V·ªõi ownership**:
   - ‚úÖ Ch·ªâ m·ªôt node x·ª≠ l√Ω session t·∫°i m·ªôt th·ªùi ƒëi·ªÉm
   - ‚úÖ C√°c node kh√°c ch·ªâ ph·ª•c v·ª• l·ªãch s·ª≠ (passive)
   - ‚úÖ Kh√¥ng c√≥ race conditions
   - ‚úÖ Failover t·ª± ƒë·ªông (TTL h·∫øt h·∫°n, node kh√°c c√≥ th·ªÉ claim)

---

### 4. Multi-Node Load Distribution

```mermaid
graph LR
    subgraph "Connections"
        U1[User 1<br/>session_A]
        U2[User 2<br/>session_B]
        U3[User 3<br/>session_C]
    end
    
    subgraph "NGINX Round-Robin"
        N[NGINX]
    end
    
    subgraph "Java Nodes"
        J1[Node 1<br/>Owns: A]
        J2[Node 2<br/>Owns: B]
        J3[Node 3<br/>Owns: C]
    end
    
    subgraph "Redis"
        R1[session:owner:A = node-1]
        R2[session:owner:B = node-2]
        R3[session:owner:C = node-3]
    end
    
    U1 -->|Round-robin| N
    U2 -->|Round-robin| N
    U3 -->|Round-robin| N
    
    N -->|Route| J1
    N -->|Route| J2
    N -->|Route| J3
    
    J1 -.->|Claim| R1
    J2 -.->|Claim| R2
    J3 -.->|Claim| R3
    
    style J1 fill:#c8e6c9
    style J2 fill:#c8e6c9
    style J3 fill:#c8e6c9
    style R1 fill:#ffccbc
    style R2 fill:#ffccbc
    style R3 fill:#ffccbc
```

**Ph√¢n B·ªï T·∫£i:**
- NGINX: Round-robin (ph√¢n ph·ªëi lu√¢n phi√™n)
- S·ªü H·ªØu Session: Ph√¢n t√°n qua Redis locks
- M·ªói node x·ª≠ l√Ω c√°c session kh√°c nhau
- C√¢n b·∫±ng t·∫£i ho√†n h·∫£o m√† kh√¥ng c·∫ßn sticky sessions

---

## üîß Chi Ti·∫øt Implementation

### 1. T·∫ßng Frontend (React)

#### K·∫øt N·ªëi & K·∫øt N·ªëi L·∫°i WebSocket

```javascript
// useWebSocket.js
const useWebSocket = (sessionId, userId) => {
  const wsRef = useRef(null);
  const reconnectTimerRef = useRef(null);
  const [isConnected, setIsConnected] = useState(false);

  const connect = useCallback(() => {
    // X√¢y d·ª±ng WebSocket URL
    const wsUrl = `${VITE_WS_URL}?session_id=${sessionId}&user_id=${userId}`;
    
    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('WebSocket connected');
      setIsConnected(true);
      // X√≥a b·ªô ƒë·∫øm k·∫øt n·ªëi l·∫°i khi k·∫øt n·ªëi th√†nh c√¥ng
      if (reconnectTimerRef.current) {
        clearTimeout(reconnectTimerRef.current);
      }
    };

    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      
      if (data.type === 'welcome') {
        console.log('Received welcome:', data);
      } else if (data.type === 'history') {
        onHistoryReceived(data.messages);
      } else if (data.type === 'message') {
        onMessageReceived(data.data);
      }
    };

    ws.onclose = () => {
      console.log('WebSocket disconnected');
      setIsConnected(false);
      
      // T·ª± ƒë·ªông k·∫øt n·ªëi l·∫°i sau 2 gi√¢y
      reconnectTimerRef.current = setTimeout(() => {
        console.log('Attempting to reconnect...');
        connect();
      }, 2000);
    };

    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
    };
  }, [sessionId, userId]);

  return { isConnected, connect, disconnect };
};
```

#### X·ª≠ L√Ω Tin Nh·∫Øn

```javascript
// useChat.js
const useChat = () => {
  const [messages, setMessages] = useState([]);

  const handleStreamingMessage = (message) => {
    if (message.role === 'assistant') {
      if (message.is_complete) {
        // Tin nh·∫Øn cu·ªëi c√πng - thay th·∫ø streaming b·∫±ng k·∫øt qu·∫£ cu·ªëi
        setMessages(prev => {
          const index = prev.findIndex(m => m.message_id === message.message_id);
          if (index >= 0) {
            const updated = [...prev];
            updated[index] = message;
            return updated;
          }
          return [...prev, message];
        });
      } else {
        // Chunk streaming - s·ª≠ d·ª•ng n·ªôi dung t√≠ch l≈©y t·ª´ server
        setMessages(prev => {
          const index = prev.findIndex(m => m.message_id === message.message_id);
          if (index >= 0) {
            // C·∫≠p nh·∫≠t v·ªõi n·ªôi dung t√≠ch l≈©y m·ªõi nh·∫•t
            const updated = [...prev];
            updated[index] = {
              ...message,
              content: message.content, // Server ƒë√£ t√≠ch l≈©y
            };
            return updated;
          }
          // Tin nh·∫Øn streaming m·ªõi
          return [...prev, message];
        });
      }
    }
  };

  return { messages, handleStreamingMessage };
};
```

**ƒêi·ªÉm Quan Tr·ªçng:**
- WebSocket t·ª± ƒë·ªông k·∫øt n·ªëi l·∫°i v·ªõi delay 2s
- L·ªãch s·ª≠ ƒë∆∞·ª£c t·∫£i ngay khi k·∫øt n·ªëi
- Streaming messages s·ª≠ d·ª•ng n·ªôi dung t√≠ch l≈©y t·ª´ server
- Kh√¥ng t√≠ch l≈©y tr√™n client (tr√°nh tr√πng l·∫∑p text)

---

### 2. T·∫ßng C√¢n B·∫±ng T·∫£i (NGINX)

#### C·∫•u H√¨nh

```nginx
http {
    # WebSocket upstream - Round-robin
    upstream websocket_backend {
        server java-websocket-1:8080 max_fails=3 fail_timeout=30s;
        server java-websocket-2:8080 max_fails=3 fail_timeout=30s;
        server java-websocket-3:8080 max_fails=3 fail_timeout=30s;
    }

    # AI Service upstream - Round-robin
    upstream ai_backend {
        server python-ai-1:8000 max_fails=3 fail_timeout=30s;
        server python-ai-2:8000 max_fails=3 fail_timeout=30s;
        server python-ai-3:8000 max_fails=3 fail_timeout=30s;
    }

    server {
        listen 80;

        # WebSocket endpoint
        location /ws/ {
            proxy_pass http://websocket_backend;

            # N√¢ng c·∫•p WebSocket
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";

            # Timeout cho k·∫øt n·ªëi d√†i h·∫°n
            proxy_connect_timeout 3600s;
            proxy_send_timeout 3600s;
            proxy_read_timeout 3600s;

            # T·∫Øt buffering cho real-time
            proxy_buffering off;
        }

        # REST API endpoint
        location /api/ {
            proxy_pass http://websocket_backend;
            proxy_set_header Host $host;
            proxy_buffering on;
        }

        # AI Service endpoint
        location /ai/ {
            proxy_pass http://ai_backend/;
            proxy_set_header Host $host;
        }
    }
}
```

**ƒê·∫∑c ƒêi·ªÉm:**
- ‚ùå KH√îNG d√πng `ip_hash` - Round-robin thu·∫ßn t√∫y
- ‚úÖ Ki·ªÉm tra s·ª©c kh·ªèe v·ªõi `max_fails` v√† `fail_timeout`
- ‚úÖ WebSocket upgrade headers
- ‚úÖ Timeout d√†i cho WebSocket (3600s)
- ‚úÖ T·∫Øt buffering cho streaming real-time

---

### 3. T·∫ßng Backend (Java WebSocket Server)

#### Qu·∫£n L√Ω Quy·ªÅn S·ªü H·ªØu Session

```java
@Service
public class ChatOrchestrator {
    
    @Autowired
    private RedisTemplate<String, String> redisTemplate;
    
    @Value("${stream.ownership-ttl-minutes:10}")
    private int ownershipTtlMinutes;
    
    public void startStreamingSession(String sessionId, String userId, StreamCallback callback) {
        // Y√™u c·∫ßu quy·ªÅn s·ªü h·ªØu session s·ª≠ d·ª•ng Redis SETNX
        String ownerKey = "session:owner:" + sessionId;
        Boolean claimed = redisTemplate.opsForValue()
            .setIfAbsent(ownerKey, getNodeId(), Duration.ofMinutes(ownershipTtlMinutes));
        
        if (claimed == null || !claimed) {
            log.warn("Failed to claim ownership for session: {}, already owned", sessionId);
            return;  // Node kh√°c ƒë√£ s·ªü h·ªØu session n√†y
        }
        
        log.info("Claimed ownership for session: {} by node: {}", sessionId, getNodeId());
        
        // Ch·ªâ subscribe n·∫øu ch√∫ng ta s·ªü h·ªØu session
        String channel = "chat:stream:" + sessionId;
        subscribeToChannel(channel, callback);
    }
    
    private void handleStreamComplete(ChatMessage message, StreamingContext context) {
        // ... x·ª≠ l√Ω ho√†n th√†nh ...
        
        // Gi·∫£i ph√≥ng quy·ªÅn s·ªü h·ªØu
        String ownerKey = "session:owner:" + context.session.getSessionId();
        redisTemplate.delete(ownerKey);
        log.info("Released ownership for completed session");
    }
    
    private String getNodeId() {
        return System.getenv("NODE_ID") != null 
            ? System.getenv("NODE_ID") 
            : UUID.randomUUID().toString();
    }
}
```

#### ƒêƒÉng K√Ω Redis PubSub

```java
private void subscribeToLegacyChannel(String channel, StreamingContext context) {
    MessageListener listener = (message, pattern) -> {
        try {
            String body = new String(message.getBody());
            ChatMessage chatMessage = objectMapper.readValue(body, ChatMessage.class);
            
            // Chuy·ªÉn ƒë·ªïi sang StreamChunk
            StreamChunk chunk = StreamChunk.builder()
                .messageId(chatMessage.getMessageId())
                .index(context.chunkIndex.getAndIncrement())
                .content(chatMessage.getContent())  // N·ªôi dung t√≠ch l≈©y
                .timestamp(Instant.now())
                .build();
            
            // Cache chunk
            streamCache.appendChunk(chunk.getMessageId(), chunk);
            
            // Xu·∫•t b·∫£n l√™n Kafka (async, t√πy ch·ªçn)
            if (eventPublisher != null) {
                eventPublisher.publishChunkReceived(context.session.getSessionId(), chunk);
            }
            
            // Chuy·ªÉn ti·∫øp cho WebSocket client
            context.callback.onChunk(chunk);
            
        } catch (Exception e) {
            log.error("Error processing message", e);
            context.callback.onError(e);
        }
    };
    
    ChannelTopic topic = new ChannelTopic(channel);
    listenerContainer.addMessageListener(listener, topic);
}
```

**Chi Ti·∫øt Tri·ªÉn Khai:**
- Y√™u c·∫ßu quy·ªÅn s·ªü h·ªØu v·ªõi `SETNX` (thao t√°c nguy√™n t·ª≠)
- TTL l√† 10 ph√∫t (c√≥ th·ªÉ c·∫•u h√¨nh)
- T·ª± ƒë·ªông gi·∫£i ph√≥ng khi stream ho√†n th√†nh ho·∫∑c l·ªói
- Ch·ªâ node s·ªü h·ªØu m·ªõi subscribe PubSub
- Kafka publishing l√† async (kh√¥ng ch·∫∑n ƒë∆∞·ªùng d·∫´n real-time)

---

### 4. T·∫ßng D·ªãch V·ª• AI (Python FastAPI)

#### T·∫°o Streaming

```python
class ChatService:
    async def stream_ai_response(self, session_id: str, user_id: str, user_message: str) -> str:
        message_id = str(uuid.uuid4())
        
        # ƒêƒÉng k√Ω streaming trong Redis (hi·ªÉn th·ªã cho t·∫•t c·∫£ nodes)
        redis_client.register_active_stream(session_id, message_id, ttl=300)
        
        # Ch·ªçn ph·∫£n h·ªìi
        response_text = AIService.select_response(user_message)
        
        accumulated_content = ""
        chunk_count = 0
        cancelled = False
        
        try:
            # Stream t·ª´ng t·ª´ m·ªôt
            async for chunk in AIService.generate_streaming_response(response_text):
                # Ki·ªÉm tra h·ªßy b·ªè m·ªói 10 chunks (t·ªëi ∆∞u h√≥a)
                if chunk_count % 10 == 0:
                    if redis_client.check_cancel_flag(session_id, message_id):
                        cancelled = True
                        break
                
                accumulated_content += chunk
                chunk_count += 1
                
                # T·∫°o tin nh·∫Øn v·ªõi n·ªôi dung t√≠ch l≈©y
                stream_message = ChatMessage.create_assistant_message(
                    message_id=message_id,
                    session_id=session_id,
                    user_id=user_id,
                    content=accumulated_content,  # To√†n b·ªô vƒÉn b·∫£n t√≠ch l≈©y
                    is_complete=False,
                    chunk=chunk  # Ch·ªâ t·ª´ hi·ªán t·∫°i
                )
                
                # Xu·∫•t b·∫£n l√™n Redis PubSub
                redis_client.publish_message(session_id, stream_message)
                
                await asyncio.sleep(0.01)  # Delay nh·ªè
            
            # G·ª≠i tin nh·∫Øn cu·ªëi c√πng
            if not cancelled:
                final_message = ChatMessage.create_assistant_message(
                    message_id=message_id,
                    session_id=session_id,
                    user_id=user_id,
                    content=accumulated_content,
                    is_complete=True
                )
                redis_client.publish_message(session_id, final_message)
                redis_client.save_to_history(session_id, final_message)
                
        finally:
            # D·ªçn d·∫πp
            redis_client.clear_active_stream(session_id)
            redis_client.clear_cancel_flag(session_id, message_id)
        
        return message_id
```

#### H·ªßy B·ªè Ph√¢n T√°n

```python
def cancel_streaming(self, session_id: str, message_id: str) -> bool:
    # Ki·ªÉm tra stream ƒëang ho·∫°t ƒë·ªông trong Redis
    active_message_id = redis_client.get_active_stream(session_id)
    
    if active_message_id and active_message_id == message_id:
        # ƒê·∫∑t c·ªù h·ªßy (hi·ªÉn th·ªã cho t·∫•t c·∫£ nodes)
        redis_client.set_cancel_flag(session_id, message_id, ttl=60)
        return True
    
    return False

# Trong RedisClient
def set_cancel_flag(self, session_id: str, message_id: str, ttl: int):
    key = f"streaming:cancel:{session_id}:{message_id}"
    self.client.setex(key, ttl, "1")

def check_cancel_flag(self, session_id: str, message_id: str) -> bool:
    key = f"streaming:cancel:{session_id}:{message_id}"
    return self.client.exists(key) > 0
```

**T√≠nh NƒÉng Ch√≠nh:**
- N·ªôi dung ƒë∆∞·ª£c t√≠ch l≈©y tr√™n server (kh√¥ng ph·∫£i client)
- H·ªßy b·ªè qua Redis (ho·∫°t ƒë·ªông tr√™n t·∫•t c·∫£ c√°c nodes)
- Ki·ªÉm tra h·ªßy m·ªói 10 chunks (t·ªëi ∆∞u h√≥a)
- Streaming b·∫•t ƒë·ªìng b·ªô v·ªõi `asyncio`

---

## üóÑÔ∏è Infrastructure Layer

### C·∫•u Tr√∫c D·ªØ Li·ªáu Redis

```mermaid
graph TB
    subgraph "Redis Keys"
        subgraph "PubSub Channels"
            PC1["chat:stream:{session_id}<br/>Real-time chunks"]
        end
        
        subgraph "History Storage"
            H1["chat:history:{session_id}<br/>List: LPUSH/LRANGE<br/>TTL: 24 hours"]
        end
        
        subgraph "Session Ownership"
            O1["session:owner:{session_id}<br/>String: SETNX<br/>TTL: 10 minutes<br/>Value: node_id"]
        end
        
        subgraph "Streaming State"
            S1["streaming:active:{session_id}<br/>String: message_id<br/>TTL: 5 minutes"]
            S2["streaming:cancel:{session}:{msg}<br/>String: flag<br/>TTL: 60 seconds"]
        end
        
        subgraph "L2 Cache"
            C1["cache:message:{message_id}<br/>String: JSON<br/>TTL: 5 minutes"]
            C2["cache:session:{session_id}<br/>String: JSON<br/>TTL: 10 minutes"]
        end
    end
    
    style PC1 fill:#ffccbc
    style H1 fill:#c5e1a5
    style O1 fill:#fff59d
    style S1 fill:#b39ddb
    style S2 fill:#b39ddb
    style C1 fill:#90caf9
    style C2 fill:#90caf9
```

#### M·∫´u S·ª≠ D·ª•ng

**1. PubSub (Nh·∫Øn Tin Real-time)**
```redis
# Xu·∫•t b·∫£n chunk
PUBLISH chat:stream:session_123 '{"content":"Hello","chunk":"world"}'

# Subscribe (Java nodes)
SUBSCRIBE chat:stream:session_123
```

**2. L∆∞u Tr·ªØ L·ªãch S·ª≠**
```redis
# L∆∞u tin nh·∫Øn
LPUSH chat:history:session_123 '{"role":"assistant","content":"..."}'
EXPIRE chat:history:session_123 86400  # 24 gi·ªù

# L·∫•y l·ªãch s·ª≠
LRANGE chat:history:session_123 0 -1
```

**3. Quy·ªÅn S·ªü H·ªØu Session**
```redis
# Y√™u c·∫ßu quy·ªÅn s·ªü h·ªØu (nguy√™n t·ª≠)
SETNX session:owner:session_123 "node-1"
EXPIRE session:owner:session_123 600  # 10 ph√∫t

# Ki·ªÉm tra ch·ªß s·ªü h·ªØu
GET session:owner:session_123

# Gi·∫£i ph√≥ng quy·ªÅn s·ªü h·ªØu
DEL session:owner:session_123
```

**4. Tr·∫°ng Th√°i Ph√¢n T√°n**
```redis
# ƒêƒÉng k√Ω stream ho·∫°t ƒë·ªông
SET streaming:active:session_123 "msg-456" EX 300

# ƒê·∫∑t c·ªù h·ªßy
SET streaming:cancel:session_123:msg-456 "1" EX 60

# Ki·ªÉm tra h·ªßy
EXISTS streaming:cancel:session_123:msg-456
```

---

### Event Sourcing V·ªõi Kafka

```mermaid
graph LR
    subgraph "Producers"
        Java[Java Nodes<br/>EventPublisher]
    end
    
    subgraph "Kafka Topics"
        T1[chat-events<br/>Partitions: 3<br/>Retention: 7 days]
        T2[stream-events<br/>Partitions: 3<br/>Retention: 7 days]
    end
    
    subgraph "Consumers"
        C1[AuditTrailConsumer<br/>‚Üí H2 audit_logs]
        C2[AnalyticsConsumer<br/>‚Üí Metrics]
        C3[CustomConsumer<br/>‚Üí Your logic]
    end
    
    Java -->|Async publish| T1
    Java -->|Async publish| T2
    
    T1 --> C1
    T1 --> C2
    T1 --> C3
    
    T2 --> C1
    T2 --> C2
    T2 --> C3
    
    style Java fill:#c8e6c9
    style T1 fill:#d1c4e9
    style T2 fill:#d1c4e9
    style C1 fill:#ffccbc
    style C2 fill:#ffccbc
    style C3 fill:#ffccbc
```

#### C√°c Lo·∫°i S·ª± Ki·ªán

**chat-events topic:**
```json
{
  "eventType": "CHAT_MESSAGE",
  "timestamp": "2024-01-01T00:00:00Z",
  "sessionId": "session_123",
  "userId": "user_abc",
  "messageId": "msg_xyz",
  "conversationId": "conv_456",
  "role": "ASSISTANT",
  "content": "Hello world",
  "metadata": {
    "nodeId": "node-1",
    "duration": 2500
  }
}
```

**stream-events topic:**
```json
{
  "eventType": "STREAM_COMPLETED",
  "timestamp": "2024-01-01T00:00:10Z",
  "sessionId": "session_123",
  "messageId": "msg_xyz",
  "totalChunks": 42,
  "contentLength": 256,
  "durationMs": 2500
}
```

#### Lu·ªìng S·ª± Ki·ªán

```mermaid
sequenceDiagram
    participant Java as Java Node
    participant Kafka as Kafka Topics
    participant Audit as AuditConsumer
    participant Analytics as AnalyticsConsumer
    participant DB as H2 Database

    Java->>Kafka: Publish SESSION_STARTED
    Java->>Kafka: Publish CHUNK_RECEIVED (x10)
    Java->>Kafka: Publish STREAM_COMPLETED
    
    Note over Kafka: Events stored<br/>Retention: 7 days
    
    par Parallel consumption
        Kafka->>Audit: Consume events
        Audit->>DB: Save to audit_logs table
    and
        Kafka->>Analytics: Consume events
        Analytics->>Analytics: Calculate metrics
        Note over Analytics: Log metrics<br/>[METRIC] logs
    end
```

**L·ª£i √çch:**
- ‚úÖ D·∫•u v·∫øt ki·ªÉm to√°n ƒë·∫ßy ƒë·ªß cho tu√¢n th·ªß
- ‚úÖ Ph√¢n t√≠ch v√† gi√°m s√°t real-time
- ‚úÖ Ph√°t l·∫°i stream ƒë·ªÉ debug v·∫•n ƒë·ªÅ
- ‚úÖ M·∫´u event sourcing
- ‚úÖ X·ª≠ l√Ω b·∫•t ƒë·ªìng b·ªô (kh√¥ng ·∫£nh h∆∞·ªüng ƒë·ªô tr·ªÖ)

---

### ƒê·∫∑c ƒêi·ªÉm Kh·∫£ NƒÉng M·ªü R·ªông

```mermaid
graph TB
    subgraph "Single Node Capacity"
        S1[1 Java Node<br/>~1000 concurrent users<br/>~5000 WebSocket connections]
        S2[1 Python Node<br/>~500 concurrent streams<br/>~100 req/sec]
        S3[1 Redis Instance<br/>~10K ops/sec<br/>~1GB memory]
    end
    
    subgraph "3-Node Cluster"
        M1[3 Java Nodes<br/>~3000 concurrent users<br/>~15000 WebSocket connections]
        M2[3 Python Nodes<br/>~1500 concurrent streams<br/>~300 req/sec]
        M3[1 Redis Shared<br/>~30K ops/sec<br/>~3GB memory]
    end
    
    subgraph "9-Node Cluster"
        L1[9 Java Nodes<br/>~9000 concurrent users<br/>~45000 WebSocket connections]
        L2[9 Python Nodes<br/>~4500 concurrent streams<br/>~900 req/sec]
        L3[Redis Cluster<br/>~100K ops/sec<br/>~10GB memory]
    end
    
    style S1 fill:#c8e6c9
    style S2 fill:#f8bbd0
    style S3 fill:#ffccbc
    style M1 fill:#c8e6c9
    style M2 fill:#f8bbd0
    style M3 fill:#ffccbc
    style L1 fill:#c8e6c9
    style L2 fill:#f8bbd0
    style L3 fill:#ffccbc
```

**M·ªü R·ªông Theo Chi·ªÅu Ngang:**
- Th√™m Java nodes: M·ªü r·ªông tuy·∫øn t√≠nh (stateless)
- Th√™m Python nodes: M·ªü r·ªông tuy·∫øn t√≠nh (stateless)
- Redis: M·ªü r·ªông theo chi·ªÅu d·ªçc tr∆∞·ªõc, sau ƒë√≥ cluster mode
- Kafka: Th√™m brokers v√† partitions

**ƒêi·ªÉm Ngh·∫Ωn:**
1. Redis single instance (~30K ops/sec gi·ªõi h·∫°n)
   - Gi·∫£i ph√°p: Redis Cluster v·ªõi sharding
2. Gi·ªõi h·∫°n k·∫øt n·ªëi NGINX (~50K)
   - Gi·∫£i ph√°p: Nhi·ªÅu NGINX instances
3. Ghi c∆° s·ªü d·ªØ li·ªáu (H2 in-memory)
   - Gi·∫£i ph√°p: PostgreSQL cluster

---

## üîê Security Considerations

### Tri·ªÉn Khai Hi·ªán T·∫°i (PoC)

```mermaid
graph LR
    subgraph "Security Layers"
        A[Client] -->|JWT Token<br/>query param| B[WebSocket]
        B -->|Validate| C[SecurityValidator]
        C -->|Extract user| D[Process Request]
    end
    
    subgraph "Development Mode"
        E[No Token] -->|Allow| F[dev-token]
    end
    
    style C fill:#ffccbc
    style E fill:#fff59d
```

**X√°c Th·ª±c JWT:**
```java
@Service
public class SecurityValidator {
    
    @Value("${security.jwt.secret}")
    private String jwtSecret;
    
    public boolean validateToken(String token) {
        try {
            Jwts.parser()
                .setSigningKey(jwtSecret)
                .parseClaimsJws(token);
            return true;
        } catch (Exception e) {
            return false;
        }
    }
    
    public String extractUserId(String token) {
        Claims claims = Jwts.parser()
            .setSigningKey(jwtSecret)
            .parseClaimsJws(token)
            .getBody();
        return claims.getSubject();
    }
}
```

### Khuy·∫øn Ngh·ªã Cho Production

**1. HTTPS/WSS (B·∫£o M·∫≠t K·∫øt N·ªëi):**
```nginx
server {
    listen 443 ssl http2;
    ssl_certificate /etc/ssl/certs/cert.pem;
    ssl_certificate_key /etc/ssl/private/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    
    location /ws/ {
        proxy_pass http://websocket_backend;
        # N√¢ng c·∫•p WebSocket qua TLS
    }
}
```

**2. Token Trong Headers:**
```javascript
// T·ªÜ: Token trong URL (hi·ªÉn th·ªã trong logs)
ws://host/ws?token=xyz

// T·ªêt: Token trong tin nh·∫Øn sau khi k·∫øt n·ªëi
ws.onopen = () => {
    ws.send(JSON.stringify({
        type: 'auth',
        token: jwtToken
    }));
};
```

**3. Gi·ªõi H·∫°n T·ªëc ƒê·ªô:**
```java
@Service
public class RateLimitService {
    private final Cache<String, AtomicInteger> requestCounts;
    
    public boolean allowRequest(String userId) {
        AtomicInteger count = requestCounts.get(userId);
        return count.incrementAndGet() <= 100;  // 100 y√™u c·∫ßu/ph√∫t
    }
}
```

**4. X√°c Th·ª±c ƒê·∫ßu V√†o:**
```java
@NotBlank
@Size(min = 1, max = 5000)
private String message;

@Pattern(regexp = "^[a-zA-Z0-9-]+$")
private String sessionId;
```

---

## üìö Best Practices & Lessons Learned

### ‚úÖ N√™n L√†m

**1. S·ª≠ D·ª•ng Kh√≥a Ph√¢n T√°n Cho Quy·ªÅn S·ªü H·ªØu Session**
```java
// T·ªêT: Redis SETNX cho y√™u c·∫ßu nguy√™n t·ª≠
Boolean claimed = redisTemplate.opsForValue()
    .setIfAbsent(ownerKey, nodeId, Duration.ofMinutes(10));

if (claimed) {
    processSession();
}
```

**2. T√≠ch L≈©y N·ªôi Dung Tr√™n Server**
```python
# T·ªêT: Server t√≠ch l≈©y, client ch·ªâ hi·ªÉn th·ªã
accumulated_content += chunk
message = {
    "content": accumulated_content,  # To√†n b·ªô vƒÉn b·∫£n
    "chunk": chunk  # T·ª´ hi·ªán t·∫°i
}
```

**3. Ki·ªÉm Tra H·ªßy B·ªè ƒê·ªãnh K·ª≥**
```python
# T·ªêT: Ki·ªÉm tra m·ªói 10 chunks (gi·∫£m l·∫ßn g·ªçi Redis)
if chunk_count % 10 == 0:
    if redis_client.check_cancel_flag(session_id, message_id):
        cancelled = True
        break
```

**4. Xu·∫•t B·∫£n Kafka B·∫•t ƒê·ªìng B·ªô**
```java
// T·ªêT: Fire and forget (kh√¥ng ch·∫∑n)
CompletableFuture.runAsync(() -> {
    eventPublisher.publishChunkReceived(session, chunk);
});
```

**5. Ghi ƒê·ªìng B·ªô Theo Session**
```java
// T·ªêT: Kh√≥a theo session (kh√¥ng to√†n c·ª•c)
Object lock = sessionLocks.computeIfAbsent(sessionId, k -> new Object());
synchronized (lock) {
    wsSession.sendMessage(textMessage);
}
```

---

### ‚ùå Kh√¥ng N√™n L√†m

**1. Kh√¥ng S·ª≠ D·ª•ng Sticky Sessions**
```nginx
# T·ªÜ: ip_hash g√¢y ph√¢n b·ªë kh√¥ng ƒë·ªÅu
upstream backend {
    ip_hash;
    server node1:8080;
}

# T·ªêT: Round-robin + quy·ªÅn s·ªü h·ªØu ph√¢n t√°n
upstream backend {
    server node1:8080;
    server node2:8080;
}
```

**2. Kh√¥ng T√≠ch L≈©y Tr√™n Client**
```javascript
// T·ªÜ: T√≠ch l≈©y ph√≠a client g√¢y tr√πng l·∫∑p
const [content, setContent] = useState('');
setContent(prev => prev + message.chunk);  // ‚ùå

// T·ªêT: S·ª≠ d·ª•ng n·ªôi dung t√≠ch l≈©y t·ª´ server
setMessages(prev => {
    updated[index] = message;  // C√≥ to√†n b·ªô n·ªôi dung
    return updated;
});
```

**3. Kh√¥ng Ch·∫∑n ƒê∆∞·ªùng D·∫´n Real-time**
```java
// T·ªÜ: L·ªánh g·ªçi Kafka ch·∫∑n trong ƒë∆∞·ªùng streaming
kafkaTemplate.send(topic, event).get();  // ‚ùå Ch·∫∑n!
sendToWebSocket(message);

// T·ªêT: Xu·∫•t b·∫£n Kafka b·∫•t ƒë·ªìng b·ªô
kafkaTemplate.send(topic, event);  // Fire and forget
sendToWebSocket(message);
```

**4. Kh√¥ng S·ª≠ D·ª•ng Kh√≥a To√†n C·ª•c**
```java
// T·ªÜ: Kh√≥a to√†n c·ª•c gi·∫øt ch·∫øt ƒë·ªìng th·ªùi
synchronized(this) {  // ‚ùå
    processAllSessions();
}

// T·ªêT: Kh√≥a chi ti·∫øt theo session
Object lock = sessionLocks.get(sessionId);
synchronized(lock) {
    processSession(sessionId);
}
```

**5. Kh√¥ng Qu√™n D·ªçn D·∫πp**
```java
// T·ªÜ: Kh√¥ng d·ªçn d·∫πp = r√≤ r·ªâ b·ªô nh·ªõ
activeStreams.put(sessionId, context);
// ... x·ª≠ l√Ω ...
// ‚ùå Qu√™n x√≥a!

// T·ªêT: Lu√¥n d·ªçn d·∫πp trong finally
try {
    processStream();
} finally {
    activeStreams.remove(sessionId);
    redisTemplate.delete(ownerKey);
}
```

---

## üöÄ Deployment Guide

### Tri·ªÉn Khai ƒê∆°n Node

```bash
# Kh·ªüi ƒë·ªông ƒë∆°n instance
docker-compose up --build

# C√°c d·ªãch v·ª• ƒë√£ kh·ªüi ƒë·ªông:
# - Redis: 6379
# - Kafka: 9092, 9093
# - Python AI: 8000
# - Java WebSocket: 8080
# - Frontend: 3000

# Truy c·∫≠p:
# - ·ª®ng d·ª•ng: http://localhost:3000
# - H2 Console: http://localhost:8080/h2-console
# - Kafka UI: http://localhost:8090 (v·ªõi --profile debug)
```

### Tri·ªÉn Khai ƒêa Node

```bash
# Kh·ªüi ƒë·ªông cluster 3 node
docker-compose -f docker-compose.multi-node.yml up --build

# C√°c d·ªãch v·ª• ƒë√£ kh·ªüi ƒë·ªông:
# - Redis: 6379 (chia s·∫ª)
# - Kafka: 9092, 9093 (chia s·∫ª)
# - Python AI Nodes: 8001, 8002, 8003
# - Java WS Nodes: 8081, 8082, 8083
# - NGINX LB: 8080
# - Frontend: 3000

# Truy c·∫≠p:
# - ·ª®ng d·ª•ng: http://localhost:3000
# - API: http://localhost:8080/api (c√¢n b·∫±ng t·∫£i)
# - WebSocket: ws://localhost:8080/ws/chat (c√¢n b·∫±ng t·∫£i)
```

### Bi·∫øn M√¥i Tr∆∞·ªùng

```yaml
# Java WebSocket Server
SPRING_DATA_REDIS_HOST: redis
SPRING_KAFKA_ENABLED: true
NODE_ID: ws-node-1
LOG_LEVEL: INFO
CACHE_L1_MAX_SIZE: 10000
STREAM_RECOVERY_TIMEOUT: 5

# D·ªãch V·ª• AI Python
REDIS_HOST: redis
NODE_ID: ai-node-1
LOG_LEVEL: INFO

# Frontend
VITE_WS_URL: ws://localhost:8080/ws/chat
VITE_API_URL: http://localhost:8080/api
```

---

## üìà Monitoring & Observability

### Thu Th·∫≠p S·ªë Li·ªáu

```java
@Service
public class MetricsService {
    
    public void recordWebSocketConnection(String sessionId, String userId) {
        log.info("[METRIC] websocket.connection.established | sessionId={} | userId={}", 
                 sessionId, userId);
    }
    
    public void recordStreamCompleted(String sessionId, int chunks, long durationMs) {
        log.info("[METRIC] message.streaming.completed | sessionId={} | chunks={} | duration={}ms", 
                 sessionId, chunks, durationMs);
    }
    
    public void recordCacheHit(String type, String key) {
        log.debug("[METRIC] cache.hit | type={} | key={}", type, key);
    }
}
```

### Ph√¢n T√≠ch Log

```bash
# Xem s·ªë li·ªáu
docker logs demo-java-websocket | grep "\[METRIC\]"

# K·∫øt qu·∫£ mong ƒë·ª£i:
[METRIC] websocket.connection.established | sessionId=abc | userId=user1
[METRIC] message.streaming.started | sessionId=abc | messageId=xyz
[METRIC] message.streaming.completed | sessionId=abc | chunks=42 | duration=2500ms
[METRIC] cache.hit | type=L1 | key=message:xyz
```

### Ki·ªÉm Tra S·ª©c Kh·ªèe

```bash
# Ki·ªÉm tra s·ª©c kh·ªèe Java backend
curl http://localhost:8080/actuator/health

# Ph·∫£n h·ªìi:
{
  "status": "UP",
  "components": {
    "redis": {"status": "UP"},
    "diskSpace": {"status": "UP"}
  }
}

# Ki·ªÉm tra s·ª©c kh·ªèe Python AI
curl http://localhost:8000/health

# Ph·∫£n h·ªìi:
{
  "status": "healthy",
  "redis": "connected",
  "timestamp": "2024-01-01T00:00:00Z"
}
```

---

## üéØ Conclusion

### ƒêi·ªÉm M·∫°nh C·ªßa Gi·∫£i Ph√°p

1. **Hi·ªáu NƒÉng Real-time**
   - ‚úÖ TTFB < 120ms
   - ‚úÖ ƒê·ªô tr·ªÖ streaming < 50ms m·ªói chunk
   - ‚úÖ Ng∆∞·ªùi d√πng ƒë·ªìng th·ªùi: 1000+ m·ªói node

2. **ƒê·ªô Tin C·∫≠y**
   - ‚úÖ T·ª± ƒë·ªông k·∫øt n·ªëi l·∫°i
   - ‚úÖ Kh√¥ng m·∫•t d·ªØ li·ªáu khi reload
   - ‚úÖ Quy·ªÅn s·ªü h·ªØu session ngƒÉn tr√πng l·∫∑p
   - ‚úÖ Event sourcing v·ªõi Kafka

3. **Kh·∫£ NƒÉng M·ªü R·ªông**
   - ‚úÖ M·ªü r·ªông theo chi·ªÅu ngang (stateless)
   - ‚úÖ Kh√¥ng c·∫ßn sticky session
   - ‚úÖ TƒÉng hi·ªáu nƒÉng tuy·∫øn t√≠nh

4. **Tr·∫£i Nghi·ªám Ph√°t Tri·ªÉn**
   - ‚úÖ Ki·∫øn tr√∫c s·∫°ch
   - ‚úÖ D·ªÖ hi·ªÉu v√† b·∫£o tr√¨
   - ‚úÖ T√†i li·ªáu ƒë·∫ßy ƒë·ªß v·ªõi bi·ªÉu ƒë·ªì
   - ‚úÖ C√°c th√†nh ph·∫ßn c√≥ th·ªÉ ki·ªÉm th·ª≠

### B√†i H·ªçc Quan Tr·ªçng

1. **Kh√¥ng C·∫ßn Sticky Session**: Quy·ªÅn s·ªü h·ªØu ph√¢n t√°n qua Redis ho·∫°t ƒë·ªông t·ªët h∆°n
2. **T√≠ch L≈©y Ph√≠a Server**: Client ƒë∆°n gi·∫£n h∆°n, ƒë√°ng tin c·∫≠y h∆°n
3. **Kafka B·∫•t ƒê·ªìng B·ªô**: Kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn hi·ªáu nƒÉng real-time
4. **Ki·ªÉm Tra H·ªßy ƒê·ªãnh K·ª≥**: C√¢n b·∫±ng gi·ªØa kh·∫£ nƒÉng ph·∫£n h·ªìi v√† chi ph√≠
5. **Kh√≥a Theo Session**: ƒê·ªìng th·ªùi t·ªët h∆°n kh√≥a to√†n c·ª•c

---

## üìû T√†i Li·ªáu B·ªï Sung

### T·∫≠p Tin T√†i Li·ªáu
- `README.md` - H∆∞·ªõng d·∫´n nhanh v√† quick start guide

### T·∫≠p Tin C·∫•u H√¨nh
- `docker-compose.yml` - Single-node setup
- `docker-compose.multi-node.yml` - Multi-node setup
- `nginx-lb.conf` - NGINX configuration
- `application.yml` - Java Spring configuration

### T·∫≠p Tin M√£ Ngu·ªìn Ch√≠nh
```
java-websocket-server/src/main/java/com/demo/websocket/
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ ChatOrchestrator.java          # Session ownership & streaming
‚îÇ   ‚îú‚îÄ‚îÄ RecoveryService.java           # Stream recovery
‚îÇ   ‚îî‚îÄ‚îÄ SessionManager.java            # WebSocket session tracking
‚îú‚îÄ‚îÄ service/
‚îÇ   ‚îú‚îÄ‚îÄ EventPublisher.java            # Kafka publishing
‚îÇ   ‚îî‚îÄ‚îÄ MetricsService.java            # Metrics collection
‚îî‚îÄ‚îÄ handler/
    ‚îî‚îÄ‚îÄ ChatWebSocketHandler.java      # WebSocket handler

python-ai-service/
‚îú‚îÄ‚îÄ ai_service.py                       # AI generation & streaming
‚îú‚îÄ‚îÄ redis_client.py                     # Redis operations
‚îî‚îÄ‚îÄ app.py                              # FastAPI endpoints

frontend/src/
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îú‚îÄ‚îÄ useWebSocket.js                 # WebSocket management
‚îÇ   ‚îî‚îÄ‚îÄ useChat.js                      # Chat state management
‚îî‚îÄ‚îÄ components/
    ‚îú‚îÄ‚îÄ MessageList.jsx                 # Message display
    ‚îî‚îÄ‚îÄ ChatInput.jsx                   # User input
```
