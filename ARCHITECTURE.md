# ğŸ—ï¸ Kiáº¿n trÃºc PoC: AI Streaming Chat vá»›i Persistent History

## ğŸ“‹ Tá»•ng quan dá»± Ã¡n

### Váº¥n Ä‘á» giáº£i quyáº¿t (Problem Statement)

**BÃ i toÃ¡n:** LÃ m tháº¿ nÃ o Ä‘á»ƒ xÃ¢y dá»±ng há»‡ thá»‘ng chat AI streaming cÃ³ kháº£ nÄƒng:
1. âœ… Stream real-time response tá»« AI Ä‘áº¿n nhiá»u clients Ä‘á»“ng thá»i
2. âœ… LÆ°u trá»¯ vÃ  khÃ´i phá»¥c lá»‹ch sá»­ chat khi user reload trang
3. âœ… Xá»­ lÃ½ reconnection vÃ  recovery khi máº¥t káº¿t ná»‘i
4. âœ… Scale horizontal vá»›i multi-node deployment
5. âœ… Äáº£m báº£o message ordering vÃ  consistency

### Giáº£i phÃ¡p (Solution)

PoC nÃ y triá»ƒn khai má»™t **Event-Driven Microservices Architecture** vá»›i:
- **Real-time Messaging**: Redis PubSub cho streaming communication
- **Persistent Storage**: Redis + H2 Database cho history
- **Event Sourcing**: Kafka cho audit trail vÃ  analytics
- **WebSocket**: Bidirectional communication vá»›i auto-reconnection
- **Load Balancing**: NGINX cho multi-node deployment

---

## ğŸ¯ Má»¥c tiÃªu PoC

### Chá»©ng minh (Proof of Concept)

1. **Streaming Architecture**
   - AI response Ä‘Æ°á»£c stream real-time qua WebSocket
   - Chunk-based transmission vá»›i low latency
   - Support concurrent users vÃ  sessions

2. **Persistence & Recovery**
   - Chat history Ä‘Æ°á»£c lÆ°u trá»¯ persistent
   - Auto-recovery khi reload page
   - Reconnection handling vá»›i resume capability

3. **Distributed System**
   - Multi-node deployment (3 Java nodes + 3 Python nodes)
   - Load balancing vÃ  failover
   - Session affinity vá»›i sticky sessions

4. **Scalability**
   - Horizontal scaling cá»§a tá»«ng component
   - Stateless services vá»›i shared state trong Redis
   - Message queue Ä‘á»ƒ decouple services

---

## ğŸ›ï¸ Kiáº¿n trÃºc tá»•ng quan

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            CLIENT LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   React Frontend (Port 3000)                                      â”‚  â”‚
â”‚  â”‚   - WebSocket Client vá»›i Auto-Reconnection                       â”‚  â”‚
â”‚  â”‚   - State Management (useState, useEffect)                       â”‚  â”‚
â”‚  â”‚   - History Loading & Display                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”‚ WebSocket (ws://)
                                    â”‚ REST API (http://)
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LOAD BALANCER LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   NGINX Load Balancer (Port 8080)                                â”‚  â”‚
â”‚  â”‚   - Sticky Sessions (IP Hash)                                    â”‚  â”‚
â”‚  â”‚   - Health Checks                                                â”‚  â”‚
â”‚  â”‚   - WebSocket Upgrade Support                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BACKEND SERVICE LAYER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Java WS Node1â”‚    â”‚ Java WS Node2â”‚    â”‚ Java WS Node3â”‚             â”‚
â”‚  â”‚  Port 8081   â”‚    â”‚  Port 8082   â”‚    â”‚  Port 8083   â”‚             â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚             â”‚
â”‚  â”‚ - WebSocket  â”‚    â”‚ - WebSocket  â”‚    â”‚ - WebSocket  â”‚             â”‚
â”‚  â”‚ - History    â”‚    â”‚ - History    â”‚    â”‚ - History    â”‚             â”‚
â”‚  â”‚ - Streaming  â”‚    â”‚ - Streaming  â”‚    â”‚ - Streaming  â”‚             â”‚
â”‚  â”‚ - Recovery   â”‚    â”‚ - Recovery   â”‚    â”‚ - Recovery   â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚               â”‚               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       AI SERVICE LAYER                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Python AI #1 â”‚    â”‚ Python AI #2 â”‚    â”‚ Python AI #3 â”‚             â”‚
â”‚  â”‚  Port 8001   â”‚    â”‚  Port 8002   â”‚    â”‚  Port 8003   â”‚             â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚             â”‚
â”‚  â”‚ - FastAPI    â”‚    â”‚ - FastAPI    â”‚    â”‚ - FastAPI    â”‚             â”‚
â”‚  â”‚ - AI Logic   â”‚    â”‚ - AI Logic   â”‚    â”‚ - AI Logic   â”‚             â”‚
â”‚  â”‚ - Streaming  â”‚    â”‚ - Streaming  â”‚    â”‚ - Streaming  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚               â”‚               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INFRASTRUCTURE LAYER                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Redis (6379)    â”‚  â”‚   Kafka (9092)     â”‚  â”‚ H2 Database     â”‚  â”‚
â”‚  â”‚                    â”‚  â”‚                    â”‚  â”‚                 â”‚  â”‚
â”‚  â”‚ - PubSub Channel   â”‚  â”‚ - Event Sourcing   â”‚  â”‚ - Message Store â”‚  â”‚
â”‚  â”‚ - History Storage  â”‚  â”‚ - Audit Trail      â”‚  â”‚ - Session Store â”‚  â”‚
â”‚  â”‚ - Session State    â”‚  â”‚ - Analytics Events â”‚  â”‚ - Metadata      â”‚  â”‚
â”‚  â”‚ - Distributed Lock â”‚  â”‚ - KRaft Mode       â”‚  â”‚                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Chi tiáº¿t Components

### 1. Frontend Layer - React Application

**CÃ´ng nghá»‡:** React 18, Vite, WebSocket API

**TrÃ¡ch nhiá»‡m:**
- Quáº£n lÃ½ WebSocket connection vá»›i auto-reconnection
- Hiá»ƒn thá»‹ chat history vÃ  streaming messages
- Handle user input vÃ  gá»­i messages
- Local state management (session_id trong localStorage)

**Key Files:**
- `frontend/src/App.jsx` - Main application component
- `frontend/src/hooks/useWebSocket.js` - Custom hook cho WebSocket management
- `frontend/src/hooks/useChat.js` - Chat logic vÃ  state management
- `frontend/src/components/MessageList.jsx` - Hiá»ƒn thá»‹ messages
- `frontend/src/components/ChatInput.jsx` - Input component

**WebSocket Connection Flow:**
```javascript
// Connection vá»›i authentication
ws://localhost:8080/ws/chat?session_id={uuid}&user_id={userId}&token={jwt}

// Auto-reconnection vá»›i exponential backoff
const RECONNECT_DELAY = 2000; // 2 seconds
const PING_INTERVAL = 30000;   // 30 seconds keep-alive
```

**Message Types Received:**
```json
{
  "type": "welcome",
  "sessionId": "uuid",
  "timestamp": "ISO-8601"
}

{
  "type": "history",
  "messages": [...]
}

{
  "type": "message",
  "data": {
    "messageId": "uuid",
    "role": "assistant",
    "content": "streaming text...",
    "isComplete": false,
    "timestamp": 1699123456789
  }
}

{
  "type": "error",
  "error": "Error message",
  "timestamp": "ISO-8601"
}
```

---

### 2. Load Balancer Layer - NGINX

**CÃ´ng nghá»‡:** NGINX Alpine

**Configuration File:** `nginx-lb.conf`

**TrÃ¡ch nhiá»‡m:**
- Load balance WebSocket connections Ä‘áº¿n Java nodes
- Proxy API requests Ä‘áº¿n AI services
- Health checks cho backend nodes
- Sticky sessions Ä‘á»ƒ maintain WebSocket connections

**Key Configuration:**
```nginx
# WebSocket load balancing vá»›i sticky sessions
upstream websocket_backend {
    ip_hash;  # Sticky sessions based on client IP
    server java-websocket-1:8080 max_fails=3 fail_timeout=30s;
    server java-websocket-2:8080 max_fails=3 fail_timeout=30s;
    server java-websocket-3:8080 max_fails=3 fail_timeout=30s;
}

# AI service load balancing (round-robin)
upstream ai_backend {
    server python-ai-1:8000 max_fails=3 fail_timeout=30s;
    server python-ai-2:8000 max_fails=3 fail_timeout=30s;
    server python-ai-3:8000 max_fails=3 fail_timeout=30s;
}

# WebSocket upgrade headers
location /ws/ {
    proxy_pass http://websocket_backend;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "Upgrade";
    proxy_set_header Host $host;
}
```

---

### 3. Backend Service Layer - Java WebSocket Server

**CÃ´ng nghá»‡:** Java 17, Spring Boot 3.2, WebSocket, Redis, Kafka

**Architecture Pattern:** Event-Driven, Layered Architecture

#### 3.1. Core Components

##### **ChatWebSocketHandler** (`handler/ChatWebSocketHandler.java`)

**TrÃ¡ch nhiá»‡m:**
- Handle WebSocket lifecycle (connect, disconnect, error)
- Gá»­i chat history khi client connect
- Forward streaming chunks tá»« Redis PubSub Ä‘áº¿n WebSocket clients
- Synchronized message sending Ä‘á»ƒ trÃ¡nh concurrent write issues
- Session recovery vÃ  reconnection handling

**Key Methods:**
```java
// Establish connection vÃ  send history
public void afterConnectionEstablished(WebSocketSession wsSession)

// Handle incoming messages (ping, reconnect, etc.)
protected void handleTextMessage(WebSocketSession wsSession, TextMessage message)

// Cleanup khi disconnect
public void afterConnectionClosed(WebSocketSession wsSession, CloseStatus status)

// Broadcast message to all clients cá»§a má»™t session
public void broadcastToSession(String sessionId, ChatMessage message)

// Synchronized sending Ä‘á»ƒ trÃ¡nh TEXT_PARTIAL_WRITING error
private void sendMessageSynchronized(WebSocketSession wsSession, String payload)
```

**WebSocket Session Management:**
```java
// Track multiple WebSocket connections per session
private final Map<String, ConcurrentHashMap<String, WebSocketSession>> sessionMap

// Per-session locks for synchronized writes
private final Map<String, Object> sessionLocks
```

---

##### **ChatOrchestrator** (`infrastructure/ChatOrchestrator.java`)

**TrÃ¡ch nhiá»‡m:**
- Orchestrate toÃ n bá»™ streaming flow
- Subscribe Redis PubSub channels
- Convert legacy messages sang new format
- Manage streaming sessions vÃ  lifecycle
- Handle completion vÃ  error scenarios

**Key Components:**
```java
// Track active streaming sessions
private final Map<String, StreamingContext> activeStreams

// Subscribe to Redis PubSub channel
public void startStreamingSession(String sessionId, String userId, StreamCallback callback)

// Handle messages tá»« Redis PubSub
private void handleLegacyMessage(ChatMessage chatMessage, StreamingContext context)

// Mark stream as complete vÃ  cleanup
private void handleStreamComplete(ChatMessage chatMessage, StreamingContext context)
```

**Distributed Session Ownership:**
```java
// Claim ownership using Redis SETNX
String ownerKey = "session:owner:" + sessionId;
Boolean claimed = redisTemplate.opsForValue()
    .setIfAbsent(ownerKey, getNodeId(), Duration.ofMinutes(10));

// Only one node handles a session at a time
if (claimed) {
    subscribeToLegacyChannel(legacyChannel, context);
}
```

---

##### **Redis Integration**

**PubSubListener** (`infrastructure/PubSubListener.java`)
- Interface for handling PubSub events
- Callbacks: onChunk(), onComplete(), onError()

**RedisMessageListener** (`service/RedisMessageListener.java`)
- Subscribe/unsubscribe Redis channels
- Fan-out messages to multiple subscribers

**RedisPubSubPublisher** (`infrastructure/RedisPubSubPublisher.java`)
- Publish chunks, complete messages, errors
- Multi-node coordination

**RedisStreamCache** (`infrastructure/RedisStreamCache.java`)
- Cache streaming chunks in Redis
- Stream recovery support
- TTL-based cleanup

**Hierarchical Cache Manager** (`service/HierarchicalCacheManager.java`)
- **L1 Cache**: Caffeine in-memory cache (fast, local)
- **L2 Cache**: Redis distributed cache (shared across nodes)
- Automatic cache synchronization

**Cache Configuration:**
```yaml
cache:
  caffeine:
    max-size: 500
    expire-after-write-minutes: 2
    expire-after-access-minutes: 1
  redis:
    default-ttl-minutes: 5
```

---

##### **Kafka Integration** (Optional)

**EventPublisher** (`service/EventPublisher.java`)

**TrÃ¡ch nhiá»‡m:**
- Publish domain events to Kafka for event sourcing
- Audit trail vÃ  analytics
- Multi-service coordination

**Event Types:**
```java
// Session events
publishSessionStarted(ChatSession session)

// Streaming events
publishChunkReceived(String sessionId, StreamChunk chunk)
publishStreamCompleted(String sessionId, Message message, int totalChunks)
publishStreamError(String sessionId, String messageId, String error)

// Recovery events
publishRecoveryAttempt(String sessionId, int fromIndex, boolean success)

// Chat events
publishChatMessage(Message message)
```

**Kafka Topics:**
- `chat-events` - Chat messages vÃ  conversations
- `stream-events` - Streaming lifecycle events

**Enable/Disable:**
```yaml
spring:
  kafka:
    enabled: true  # Set to false to disable Kafka
    bootstrap-servers: kafka:9092
```

---

##### **Recovery & Resilience**

**RecoveryService** (`infrastructure/RecoveryService.java`)

**TrÃ¡ch nhiá»‡m:**
- Recover missing chunks khi reconnect
- Check stream status (ongoing, completed, expired)
- Replay chunks from cache

**Recovery Flow:**
```java
public RecoveryResponse recoverStream(RecoveryRequest request) {
    // 1. Validate request
    // 2. Retrieve session from cache
    // 3. Get missing chunks
    // 4. Return recovery response
}
```

**Recovery Response Types:**
- `RECOVERED` - Stream Ä‘ang active, tráº£ vá» missing chunks
- `COMPLETED` - Stream Ä‘Ã£ complete, tráº£ vá» final message
- `NOT_FOUND` - Session khÃ´ng tá»“n táº¡i
- `EXPIRED` - Session Ä‘Ã£ expire
- `ERROR` - Lá»—i trong quÃ¡ trÃ¬nh recovery

---

##### **Session Management**

**SessionManager** (`infrastructure/SessionManager.java`)

**TrÃ¡ch nhiá»‡m:**
- Register/unregister WebSocket sessions
- Track session metadata (userId, startTime, lastActivity)
- Heartbeat monitoring
- Session timeout handling

**Features:**
```java
// Register session with metadata
void registerSession(String sessionId, WebSocketSession wsSession, String userId)

// Update heartbeat timestamp
void updateHeartbeat(String sessionId)

// Mark session as error state
void markSessionError(String sessionId)

// Get session info
String getSessionId(WebSocketSession wsSession)
```

---

#### 3.2. Domain Models

**Message** (`domain/Message.java`)
```java
@Entity
public class Message {
    private String id;                    // UUID
    private String conversationId;        // Group messages
    private String userId;
    private MessageRole role;             // USER, ASSISTANT, SYSTEM
    private String content;               // Message content
    private MessageStatus status;         // PENDING, STREAMING, COMPLETED, FAILED
    private Instant createdAt;
    private Instant updatedAt;
    private MessageMetadata metadata;     // Token count, model info, etc.
}
```

**StreamChunk** (`domain/StreamChunk.java`)
```java
public class StreamChunk {
    private String messageId;
    private int index;                    // Chunk sequence number
    private String content;               // Accumulated content
    private ChunkType type;               // TEXT, CODE, ERROR
    private Instant timestamp;
}
```

**ChatSession** (`domain/ChatSession.java`)
```java
public class ChatSession {
    private String sessionId;
    private String userId;
    private String messageId;             // Current streaming message
    private String conversationId;
    private SessionStatus status;         // INITIALIZING, STREAMING, COMPLETED, ERROR
    private Instant startTime;
    private Instant lastActivityTime;
    private int totalChunks;
    private StreamMetadata metadata;
}
```

---

#### 3.3. Security & Validation

**SecurityValidator** (`service/SecurityValidator.java`)

**Features:**
- JWT token validation
- Token expiration check
- User authentication
- Rate limiting per user

**JWT Configuration:**
```yaml
security:
  jwt:
    secret: ${JWT_SECRET:default-key}
    expiration-ms: 3600000  # 1 hour
```

---

#### 3.4. Monitoring & Metrics

**MetricsService** (`service/MetricsService.java`)

**Metrics Tracked:**
- WebSocket connections (connect/disconnect)
- Messages sent/received
- Streaming performance (latency, throughput)
- Error rates
- Recovery attempts
- Cache hit/miss rates

**Logging Pattern:**
```
[METRIC] websocket.connection.established | userId=demo_user | timestamp=...
[METRIC] message.streaming.completed | sessionId=xxx | chunks=42 | duration=2134ms
[METRIC] cache.hit | type=L1 | key=message:xxx
```

**Actuator Endpoints:**
```
GET /actuator/health      # Health check
GET /actuator/info        # Application info
```

---

### 4. AI Service Layer - Python FastAPI

**CÃ´ng nghá»‡:** Python 3.11, FastAPI, Redis, asyncio

**Architecture:** Clean Architecture vá»›i separation of concerns

#### 4.1. Core Components

##### **FastAPI Application** (`app.py`)

**Endpoints:**
```python
GET  /                          # Service info
GET  /health                    # Health check vá»›i Redis connection test
POST /chat                      # Trigger AI streaming response
GET  /history/{session_id}      # Get chat history
DELETE /history/{session_id}    # Clear chat history
POST /cancel                    # Cancel ongoing streaming
```

**Lifespan Management:**
```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup: Connect to Redis
    redis_client.connect()
    yield
    # Shutdown: Cleanup
```

---

##### **AI Service** (`ai_service.py`)

**AIService Class:**

**TrÃ¡ch nhiá»‡m:**
- Generate AI responses (simulated)
- Stream response word by word
- Select appropriate response based on user message

**Key Methods:**
```python
async def generate_streaming_response(text: str) -> AsyncGenerator[str, None]:
    """Stream text word by word vá»›i delay"""
    words = text.split()
    for word in words:
        await asyncio.sleep(STREAM_DELAY)
        yield word + " "

def select_response(user_message: str) -> str:
    """Select response based on keywords"""
    # Smart routing based on message content
```

**Sample Responses:**
- Greeting vÃ  general info
- Streaming architecture explanation
- Persistence vÃ  recovery details
- Redis architecture details
- Workflow vÃ  flow explanation
- Technical deep-dives

---

**ChatService Class:**

**TrÃ¡ch nhiá»‡m:**
- Process user messages
- Orchestrate AI streaming
- Handle cancellation
- Manage distributed state in Redis

**Key Methods:**
```python
async def process_user_message(session_id, user_id, message_content) -> str:
    """
    1. Create user message vá»›i UUID
    2. Save to Redis history
    3. Publish to PubSub
    4. Return message_id
    """

async def stream_ai_response(session_id, user_id, user_message) -> str:
    """
    1. Register active stream in Redis
    2. Generate response chunks
    3. Check cancellation flag periodically (every 10 chunks)
    4. Publish chunks to Redis PubSub
    5. Handle completion or cancellation
    6. Cleanup Redis tracking
    """

def cancel_streaming(session_id, message_id) -> bool:
    """
    1. Check active stream in Redis
    2. Verify message_id matches
    3. Set cancel flag in Redis (distributed)
    4. Return success/failure
    """
```

**Distributed Cancellation:**
```python
# Register streaming task in Redis (visible to all nodes)
redis_client.register_active_stream(session_id, message_id, ttl=300)

# Check cancel flag periodically (reduces Redis calls)
if chunk_count % 10 == 0:
    if redis_client.check_cancel_flag(session_id, message_id):
        cancelled = True
        break

# Set cancel flag (works across all nodes)
redis_client.set_cancel_flag(session_id, message_id, ttl=60)
```

---

##### **Redis Client** (`redis_client.py`)

**RedisClient Class:**

**TrÃ¡ch nhiá»‡m:**
- Manage Redis connections
- PubSub operations
- History storage
- Distributed state management

**Key Methods:**
```python
# Connection
def connect() -> None
def ping() -> bool

# PubSub
def publish_message(session_id: str, message: ChatMessage) -> bool
def subscribe(session_id: str, callback: Callable)

# History Storage
def save_to_history(session_id: str, message: ChatMessage)
def get_history(session_id: str) -> List[ChatMessage]
def clear_history(session_id: str) -> bool

# Distributed State (for multi-node)
def register_active_stream(session_id: str, message_id: str, ttl: int)
def get_active_stream(session_id: str) -> Optional[str]
def clear_active_stream(session_id: str)
def set_cancel_flag(session_id: str, message_id: str, ttl: int)
def check_cancel_flag(session_id: str, message_id: str) -> bool
def clear_cancel_flag(session_id: str, message_id: str)
```

**Redis Data Structures:**
```python
# PubSub Channel
CHANNEL = f"chat:stream:{session_id}"

# History List (LPUSH, LRANGE)
KEY = f"chat:history:{session_id}"
TTL = 86400  # 24 hours

# Active Stream Tracking
KEY = f"streaming:active:{session_id}"
VALUE = message_id

# Cancellation Flag
KEY = f"streaming:cancel:{session_id}:{message_id}"
VALUE = "1"
```

---

#### 4.2. Configuration

**Configuration** (`config.py`)

```python
class Settings(BaseSettings):
    # Server
    HOST: str = "0.0.0.0"
    PORT: int = 8000
    DEBUG: bool = False
    
    # Redis
    REDIS_HOST: str = "redis"
    REDIS_PORT: int = 6379
    
    # Streaming
    STREAM_DELAY: float = 0.05     # Delay between words
    CHUNK_DELAY: float = 0.01      # Delay between chunks
    
    # Storage
    HISTORY_TTL: int = 86400       # 24 hours
    
    # Logging
    LOG_LEVEL: str = "INFO"
```

---

#### 4.3. Data Models

**Models** (`models.py`)

```python
class ChatMessage(BaseModel):
    messageId: str
    sessionId: str
    userId: str
    role: str  # "user" | "assistant"
    content: str
    timestamp: int
    isComplete: bool
    chunk: Optional[str] = None

class ChatRequest(BaseModel):
    session_id: str
    message: str
    user_id: str = "default_user"

class ChatResponse(BaseModel):
    status: str
    message_id: str
    session_id: str
    message: str

class CancelRequest(BaseModel):
    session_id: str
    message_id: str

class HistoryResponse(BaseModel):
    session_id: str
    messages: List[ChatMessage]
    count: int

class HealthResponse(BaseModel):
    status: str
    redis: str
    timestamp: str
```

---

### 5. Infrastructure Layer

#### 5.1. Redis

**Version:** Redis 7 Alpine

**Use Cases:**

**1. PubSub for Real-time Streaming**
```redis
# Publish streaming chunk
PUBLISH chat:stream:{session_id} {json_message}

# Subscribe to session
SUBSCRIBE chat:stream:{session_id}
```

**2. List for History Storage**
```redis
# Save message
LPUSH chat:history:{session_id} {json_message}
EXPIRE chat:history:{session_id} 86400

# Get history
LRANGE chat:history:{session_id} 0 -1
```

**3. String for Distributed State**
```redis
# Register active stream
SET streaming:active:{session_id} {message_id} EX 300

# Set cancel flag
SET streaming:cancel:{session_id}:{message_id} "1" EX 60

# Session ownership (SETNX for distributed lock)
SET session:owner:{session_id} {node_id} NX EX 600
```

**4. Hierarchical Cache (L2)**
```redis
# Cache message
SET cache:message:{messageId} {json} EX 300

# Cache session
SET cache:session:{sessionId} {json} EX 600
```

**Configuration:**
```yaml
redis:
  image: redis:7-alpine
  ports:
    - "6379:6379"
  volumes:
    - redis-data:/data
  command: redis-server --appendonly yes
```

---

#### 5.2. Kafka

**Version:** Apache Kafka (KRaft mode - No Zookeeper)

**Use Cases:**

**1. Event Sourcing**
- Store all domain events
- Audit trail
- Replay capability

**2. Analytics**
- Track user behavior
- Performance metrics
- Business insights

**3. Multi-Service Coordination**
- Event-driven architecture
- Loose coupling
- Async processing

**Topics:**
```
chat-events         # Chat messages, conversations
stream-events       # Streaming lifecycle events
```

**Configuration:**
```yaml
kafka:
  image: apache/kafka:latest
  ports:
    - "9092:9092"  # Client connections
    - "9093:9093"  # Controller
  environment:
    KAFKA_NODE_ID: 1
    KAFKA_PROCESS_ROLES: broker,controller
    KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
    KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
    KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    KAFKA_LOG_RETENTION_HOURS: 168  # 7 days
```

**Event Examples:**
```json
{
  "eventType": "SESSION_STARTED",
  "timestamp": "2024-01-01T00:00:00Z",
  "sessionId": "uuid",
  "userId": "user123",
  "messageId": "uuid"
}

{
  "eventType": "CHUNK_RECEIVED",
  "timestamp": "2024-01-01T00:00:01Z",
  "sessionId": "uuid",
  "messageId": "uuid",
  "chunkIndex": 42,
  "contentLength": 256
}

{
  "eventType": "STREAM_COMPLETED",
  "timestamp": "2024-01-01T00:00:10Z",
  "sessionId": "uuid",
  "messageId": "uuid",
  "totalChunks": 100,
  "contentLength": 2048
}
```

---

#### 5.3. H2 Database

**Version:** H2 In-Memory Database

**Use Cases:**
- Message persistence
- Session metadata
- Audit logs
- Conversation history

**Entities:**
```sql
-- Messages table
CREATE TABLE message (
    id VARCHAR(36) PRIMARY KEY,
    conversation_id VARCHAR(36),
    user_id VARCHAR(255),
    role VARCHAR(20),
    content TEXT,
    status VARCHAR(20),
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);

-- Chat sessions table
CREATE TABLE chat_session (
    session_id VARCHAR(36) PRIMARY KEY,
    user_id VARCHAR(255),
    conversation_id VARCHAR(36),
    status VARCHAR(20),
    start_time TIMESTAMP,
    last_activity_time TIMESTAMP
);

-- Audit logs table
CREATE TABLE audit_log (
    id VARCHAR(36) PRIMARY KEY,
    session_id VARCHAR(36),
    event_type VARCHAR(50),
    event_data TEXT,
    timestamp TIMESTAMP
);

-- Stream chunks table (for recovery)
CREATE TABLE stream_chunk (
    id VARCHAR(36) PRIMARY KEY,
    message_id VARCHAR(36),
    chunk_index INTEGER,
    content TEXT,
    timestamp TIMESTAMP
);
```

**Configuration:**
```yaml
spring:
  datasource:
    url: jdbc:h2:mem:websocketdb
    driver-class-name: org.h2.Driver
  jpa:
    hibernate:
      ddl-auto: update
```

---

## ğŸ“Š Data Flow - Detailed Scenarios

### Scenario 1: Normal Streaming Flow

**Má»¥c tiÃªu:** User gá»­i message vÃ  nháº­n streaming response

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client  â”‚                                                     â”‚ Java BE â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                                                               â”‚
     â”‚  1. POST /api/chat                                           â”‚
     â”‚  {session_id, message, user_id}                              â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚                                                               â”‚
     â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
     â”‚                         â”‚Python AIâ”‚                          â”‚
     â”‚                         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚
     â”‚                              â”‚                               â”‚
     â”‚  2. POST /chat              â”‚                               â”‚
     â”‚  Proxy request to AI        â”‚                               â”‚
     â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>                               â”‚
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚  3. Save user message         â”‚
     â”‚                              â”‚  to Redis history             â”‚
     â”‚                              â”‚     â”‚                         â”‚
     â”‚                              â”‚     â–¼                         â”‚
     â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
     â”‚                         â”‚  Redis  â”‚                          â”‚
     â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚  4. Generate AI response      â”‚
     â”‚                              â”‚  (word by word)               â”‚
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚  5. For each chunk:           â”‚
     â”‚                              â”‚     - Accumulate content      â”‚
     â”‚                              â”‚     - Publish to PubSub       â”‚
     â”‚                              â”‚     PUBLISH chat:stream:{sid} â”‚
     â”‚                              â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚
     â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚                 â”‚
     â”‚                         â”‚  Redis  â”‚       â”‚                 â”‚
     â”‚                         â”‚ PubSub  â”‚       â”‚                 â”‚
     â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚                 â”‚
     â”‚                              â”‚            â”‚                 â”‚
     â”‚                              â”‚            â”‚  6. Subscribe   â”‚
     â”‚                              â”‚            â”‚  to channel     â”‚
     â”‚                              â”‚            â”‚  (if not yet)   â”‚
     â”‚                              â”‚            â”‚                 â”‚
     â”‚                              â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚  7. Receive chunk from PubSubâ”‚
     â”‚                              â”‚  Convert to StreamChunk      â”‚
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚          8. Cache chunk       â”‚
     â”‚                              â”‚          in Redis             â”‚
     â”‚                              â”‚             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚
     â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                         â”‚  Redis  â”‚       â”‚           â”‚  Cache  â”‚
     â”‚                         â”‚ Storage â”‚       â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚                 â”‚
     â”‚                              â”‚             â”‚                 â”‚
     â”‚                              â”‚             â”‚  9. Publish to  â”‚
     â”‚                              â”‚             â”‚  Kafka (optional)
     â”‚                              â”‚             â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€>
     â”‚                              â”‚             â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
     â”‚                              â”‚             â”‚   â”‚  Kafka  â”‚   â”‚
     â”‚                              â”‚             â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
     â”‚                              â”‚             â”‚                 â”‚
     â”‚  10. Send chunk via WebSocket               â”‚                 â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
     â”‚  {"type": "message",                                          â”‚
     â”‚   "data": {                                                   â”‚
     â”‚     "content": "Hello world...",                              â”‚
     â”‚     "isComplete": false                                       â”‚
     â”‚   }}                                                          â”‚
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚  11. Repeat steps 5-10        â”‚
     â”‚                              â”‚  for each word                â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚  12. Final chunk with         â”‚
     â”‚                              â”‚  isComplete: true             â”‚
     â”‚                              â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚  13. Save complete message    â”‚
     â”‚                              â”‚  to history & DB              â”‚
     â”‚                              â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚
     â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
     â”‚                         â”‚  Redis  â”‚                          â”‚
     â”‚                         â”‚   +     â”‚                          â”‚
     â”‚                         â”‚  H2 DB  â”‚                          â”‚
     â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
     â”‚                              â”‚                               â”‚
     â”‚  14. Complete message via WebSocket                          â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     â”‚  {"type": "message",                                          â”‚
     â”‚   "data": {                                                   â”‚
     â”‚     "content": "Hello world, this is complete!",              â”‚
     â”‚     "isComplete": true                                        â”‚
     â”‚   }}                                                          â”‚
     â”‚                                                               â”‚
```

**Timing:**
- Step 1-2: ~10ms (HTTP request)
- Step 3: ~5ms (Redis write)
- Step 4-11: ~2-5 seconds (streaming, 50ms per word)
- Step 12-14: ~20ms (finalization)

**Total:** 2-5 seconds for complete response

---

### Scenario 2: Reload During Streaming

**Má»¥c tiÃªu:** User reload trang trong khi AI Ä‘ang streaming

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client  â”‚                                                     â”‚ Java BE â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                                                               â”‚
     â”‚  STREAMING IN PROGRESS...                                    â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚  Chunk #1: "Hello"                                           â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚  Chunk #2: "world"                                           â”‚
     â”‚                                                               â”‚
     â”‚  âš ï¸  USER RELOADS PAGE                                       â”‚
     â”‚                                                               â”‚
     â”‚  WebSocket disconnected                                      â”‚
     â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
     â”‚                                                               â”‚
     â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
     â”‚                         â”‚Python AIâ”‚                          â”‚
     â”‚                         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚  âš ï¸ AI continues streaming    â”‚
     â”‚                              â”‚  (doesn't know about          â”‚
     â”‚                              â”‚   disconnect)                 â”‚
     â”‚                              â”‚                               â”‚
     â”‚                              â”‚  Chunk #3: "this"             â”‚
     â”‚                              â”‚  PUBLISH chat:stream:{sid}    â”‚
     â”‚                              â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚
     â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
     â”‚                         â”‚  Redis  â”‚                          â”‚
     â”‚                         â”‚ History â”‚                          â”‚
     â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
     â”‚                              â”‚  (saved to history)           â”‚
     â”‚                              â”‚                               â”‚
     â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
     â”‚  CLIENT RELOADS & RECONNECTS                                 â”‚
     â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
     â”‚                                                               â”‚
     â”‚  1. New WebSocket connection                                 â”‚
     â”‚  ws://...?session_id={same_session_id}                       â”‚
     â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
     â”‚                                                               â”‚
     â”‚  2. Welcome message                                          â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚  {"type": "welcome", "sessionId": "..."}                     â”‚
     â”‚                                                               â”‚
     â”‚  3. Request history from Redis                               â”‚
     â”‚                              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
     â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
     â”‚                         â”‚  Redis  â”‚                          â”‚
     â”‚                         â”‚ History â”‚                          â”‚
     â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
     â”‚                              â”‚                               â”‚
     â”‚  4. Send complete history (including partial streaming)     â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚  {"type": "history",                                         â”‚
     â”‚   "messages": [                                              â”‚
     â”‚     {"role": "user", "content": "...", "isComplete": true},  â”‚
     â”‚     {"role": "assistant", "content": "Hello world this",     â”‚
     â”‚      "isComplete": false}  â† Partial message                 â”‚
     â”‚   ]}                                                          â”‚
     â”‚                                                               â”‚
     â”‚  5. Subscribe to session PubSub                              â”‚
     â”‚                              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
     â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
     â”‚                         â”‚  Redis  â”‚                          â”‚
     â”‚                         â”‚ PubSub  â”‚                          â”‚
     â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
     â”‚                              â”‚                               â”‚
     â”‚  6. Continue receiving NEW chunks                            â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚  Chunk #4: "is"                                              â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚  Chunk #5: "streaming!"                                      â”‚
     â”‚                                                               â”‚
     â”‚  7. Final chunk with isComplete: true                        â”‚
     â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚  {"type": "message", "data": {                               â”‚
     â”‚    "content": "Hello world this is streaming!",              â”‚
     â”‚    "isComplete": true                                        â”‚
     â”‚  }}                                                           â”‚
     â”‚                                                               â”‚
     â”‚  âœ… USER SEES COMPLETE MESSAGE SEAMLESSLY!                   â”‚
     â”‚                                                               â”‚
```

**Key Points:**
- âœ… AI service **khÃ´ng bá»‹ interrupt** khi client disconnect
- âœ… Chunks váº«n Ä‘Æ°á»£c lÆ°u vÃ o Redis history
- âœ… Client reconnect vÃ  nháº­n **toÃ n bá»™ history** (bao gá»“m partial message)
- âœ… Client **tá»± Ä‘á»™ng subscribe** vÃ  tiáº¿p tá»¥c nháº­n streaming
- âœ… **No data loss**, seamless experience

---

### Scenario 3: Multi-Node Load Balancing

**Má»¥c tiÃªu:** 3 users connect Ä‘á»“ng thá»i, Ä‘Æ°á»£c distribute across nodes

```
User A                    User B                    User C
  â”‚                         â”‚                         â”‚
  â”‚  WebSocket Connect      â”‚                         â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€>
  â”‚                         â”‚  WebSocket Connect      â”‚       NGINX
  â”‚                         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€> LB
  â”‚                         â”‚                         â”‚       (ip_hash)
  â”‚                         â”‚                         â”‚  WS Connect
  â”‚                         â”‚                         â”œâ”€â”€â”€â”€â”€â”€â”€â”€>
  â”‚                         â”‚                         â”‚
  â–¼                         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Java Node 1  â”‚      â”‚ Java Node 2  â”‚      â”‚ Java Node 3  â”‚
â”‚ Port 8081    â”‚      â”‚ Port 8082    â”‚      â”‚ Port 8083    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚                     â”‚
       â”‚  Session A          â”‚  Session B          â”‚  Session C
       â”‚  Subscribe          â”‚  Subscribe          â”‚  Subscribe
       â”‚  chat:stream:A      â”‚  chat:stream:B      â”‚  chat:stream:C
       â”‚        â”‚            â”‚        â”‚            â”‚        â”‚
       â”‚        â–¼            â”‚        â–¼            â”‚        â–¼
       â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   â”‚         Redis PubSub (Shared)               â”‚
       â”‚   â”‚                                             â”‚
       â”‚   â”‚  Channels:                                  â”‚
       â”‚   â”‚  - chat:stream:session_A                    â”‚
       â”‚   â”‚  - chat:stream:session_B                    â”‚
       â”‚   â”‚  - chat:stream:session_C                    â”‚
       â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚                     â”‚
       â”‚                     â”‚                     â”‚
       â”‚                     â–¼                     â”‚
       â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
       â”‚                â”‚ Python AI #2 â”‚           â”‚
       â”‚                â”‚ (handles B)  â”‚           â”‚
       â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
       â”‚                     â”‚                     â”‚
       â”‚                     â”‚  PUBLISH            â”‚
       â”‚                     â”‚  chat:stream:B      â”‚
       â”‚                     â”‚                     â”‚
       â”‚                     â–¼                     â”‚
       â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   â”‚         Redis PubSub (Fanout)               â”‚
       â”‚   â”‚                                             â”‚
       â”‚   â”‚  All 3 Java nodes subscribed to:           â”‚
       â”‚   â”‚  - Node 1: session_A                       â”‚
       â”‚   â”‚  - Node 2: session_B â† Receives message    â”‚
       â”‚   â”‚  - Node 3: session_C                       â”‚
       â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚                     â”‚
       â”‚                     â–¼                     â”‚
       â”‚                Java Node 2                â”‚
       â”‚                Forwards to                â”‚
       â”‚                User B via WS              â”‚
       â”‚                     â”‚                     â”‚
       â”‚                     â–¼                     â”‚
                          User B
                     Receives streaming
                          response
```

**Load Distribution:**
- NGINX uses `ip_hash` Ä‘á»ƒ ensure sticky sessions
- Má»—i user Ä‘Æ°á»£c route Ä‘áº¿n same Java node (for WebSocket consistency)
- Python AI services Ä‘Æ°á»£c distribute round-robin (stateless)
- Redis PubSub fan-out Ä‘áº¿n táº¥t cáº£ subscribed nodes
- Only relevant nodes forward messages to their clients

**Session Ownership:**
```redis
# Node 2 claims ownership of session_B
SET session:owner:session_B "ws-node-2" NX EX 600

# Only Node 2 will subscribe to chat:stream:session_B
# Other nodes skip subscription (already owned)
```

**Scalability:**
- Add thÃªm Java nodes â†’ NGINX auto load-balance
- Add thÃªm Python AI nodes â†’ Java BE round-robin
- Redis PubSub handles unlimited subscribers
- No coordination needed between Java nodes

---

### Scenario 4: Distributed Cancellation

**Má»¥c tiÃªu:** User cancel streaming, works across all nodes

```
User A (connected to Node 1)
  â”‚
  â”‚  1. Streaming in progress...
  â”‚  Receiving chunks from AI
  â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                  Java Node 1
  â”‚                                  WebSocket Handler
  â”‚                                        â”‚
  â”‚                                        â”‚
  â”‚  2. User clicks "Cancel" button       â”‚
  â”‚                                        â”‚
  â”‚  POST /api/cancel                      â”‚
  â”‚  {session_id, message_id}              â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
  â”‚                                  ChatController
  â”‚                                        â”‚
  â”‚                                        â–¼
  â”‚                                  3. Set cancel flag
  â”‚                                  in Redis
  â”‚                                        â”‚
  â”‚                                  SET streaming:cancel:
  â”‚                                      {session}:{msg} "1"
  â”‚                                  EX 60
  â”‚                                        â”‚
  â”‚                                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
  â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                   â”‚  Redis  â”‚
  â”‚                                   â”‚ (Shared)â”‚
  â”‚                                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
  â”‚                                        â”‚
  â”‚                                        â”‚ 4. Flag is now
  â”‚                                        â”‚ visible to
  â”‚                                        â”‚ ALL nodes
  â”‚                                        â”‚
  â”‚                                        â–¼
  â”‚                                   Python AI Node 3
  â”‚                                   (Currently streaming
  â”‚                                    this message)
  â”‚                                        â”‚
  â”‚                                        â”‚ 5. Check flag
  â”‚                                        â”‚ every 10 chunks
  â”‚                                        â”‚
  â”‚    if chunk_count % 10 == 0:          â”‚
  â”‚        cancel = redis.get(            â”‚
  â”‚            f"streaming:cancel:         â”‚
  â”‚             {session}:{msg}")          â”‚
  â”‚                                        â”‚
  â”‚                                        â”‚ 6. Flag found!
  â”‚                                        â”‚ Stop streaming
  â”‚                                        â–¼
  â”‚                                   break loop
  â”‚                                        â”‚
  â”‚                                        â”‚ 7. Send cancel
  â”‚                                        â”‚ message
  â”‚                                        â”‚
  â”‚                                   PUBLISH chat:stream:
  â”‚                                           {session}
  â”‚                                   {                    
  â”‚                                     "content": "...[Cancelled]",
  â”‚                                     "isComplete": true
  â”‚                                   }
  â”‚                                        â”‚
  â”‚                                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
  â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                   â”‚  Redis  â”‚
  â”‚                                   â”‚ PubSub  â”‚
  â”‚                                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
  â”‚                                        â”‚
  â”‚                                        â–¼
  â”‚                                  Java Node 1
  â”‚                                  Receives cancel msg
  â”‚                                        â”‚
  â”‚  8. Forward cancel to user            â”‚
  â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚                                        
  â”‚  {"type": "message",
  â”‚   "data": {
  â”‚     "content": "Hello world...\n\n[ÄÃ£ há»§y]",
  â”‚     "isComplete": true
  â”‚   }}
  â”‚
  â”‚  9. Cleanup Redis flags
  â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
  â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                   â”‚  Redis  â”‚
  â”‚                                   â”‚         â”‚
  â”‚   DEL streaming:active:{session}  â”‚         â”‚
  â”‚   DEL streaming:cancel:{session}  â”‚         â”‚
  â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  âœ… Streaming cancelled successfully!
```

**Key Points:**
- âœ… Cancel request cÃ³ thá»ƒ Ä‘áº¿n **báº¥t ká»³ Java node** nÃ o (through NGINX)
- âœ… Cancel flag Ä‘Æ°á»£c set trong **Redis** (shared state)
- âœ… Python AI node (Ä‘ang streaming) **check flag periodically**
- âœ… Works **across all nodes** - true distributed cancellation
- âœ… Optimization: Check every 10 chunks (reduce Redis calls, max 0.5s delay)
- âœ… Race condition handled: Set flag even if message already completed

**Why Distributed?**
- User connects to Java Node 1 (WebSocket)
- User request proxied to Python AI Node 3 (REST API, round-robin)
- Cancel request may hit Java Node 2 (NGINX load balance)
- Redis ensures cancel flag visible to Python AI Node 3
- **All nodes coordinate through shared Redis state**

---

## ğŸ¨ Design Patterns & Best Practices

### 1. Architecture Patterns

#### **Event-Driven Architecture**
- Components communicate qua events (Redis PubSub, Kafka)
- Loose coupling, high scalability
- Async processing, non-blocking

#### **Microservices Pattern**
- Java BE vÃ  Python AI lÃ  independent services
- Each service cÃ³ responsibility riÃªng
- Can scale independently

#### **CQRS (Command Query Responsibility Segregation)**
- Write: Save messages to Redis + H2 Database
- Read: Query from cache (L1/L2) hoáº·c history
- Optimized for different access patterns

#### **Event Sourcing** (via Kafka)
- All events Ä‘Æ°á»£c stored sequentially
- Can replay events Ä‘á»ƒ rebuild state
- Audit trail cho compliance

#### **Saga Pattern** (Orchestrated)
- ChatOrchestrator Ä‘iá»u phá»‘i streaming flow
- Handle compensating transactions (cancel, error)
- Maintain data consistency across services

---

### 2. Code Organization Patterns

#### **Layered Architecture** (Java Backend)

```
Presentation Layer (Controller)
       â†“
Application Layer (Service)
       â†“
Domain Layer (Models, Repository)
       â†“
Infrastructure Layer (Redis, Kafka, DB)
```

#### **Clean Architecture** (Python Service)

```
app.py (Entry point)
    â†“
ai_service.py (Business Logic)
    â†“
redis_client.py (Infrastructure)
    â†“
models.py (Domain Models)
```

#### **Dependency Injection**
- Spring Boot's built-in DI container
- Constructor injection (recommended)
- Interface-based design

```java
public class ChatOrchestrator {
    private final RedisStreamCache streamCache;
    private final EventPublisher eventPublisher;
    
    // Constructor injection
    public ChatOrchestrator(RedisStreamCache streamCache,
                           EventPublisher eventPublisher) {
        this.streamCache = streamCache;
        this.eventPublisher = eventPublisher;
    }
}
```

---

### 3. Concurrency Patterns

#### **Actor Model** (via StreamingContext)
```java
private static class StreamingContext {
    final ChatSession session;
    final StreamCallback callback;
    final AtomicInteger chunkIndex;
    
    // Each context = isolated actor
    // No shared mutable state
}
```

#### **Producer-Consumer Pattern**
```
Python AI (Producer) â†’ Redis PubSub â†’ Java BE (Consumer) â†’ WebSocket Client
```

#### **Synchronized Messaging**
```java
// Per-session locks Ä‘á»ƒ trÃ¡nh concurrent writes
private final Map<String, Object> sessionLocks = new ConcurrentHashMap<>();

private void sendMessageSynchronized(WebSocketSession wsSession, String payload) {
    Object lock = sessionLocks.computeIfAbsent(wsSession.getId(), k -> new Object());
    synchronized (lock) {
        wsSession.sendMessage(new TextMessage(payload));
    }
}
```

---

### 4. Resilience Patterns

#### **Circuit Breaker** (Kafka optional)
```java
@ConditionalOnProperty(name = "spring.kafka.enabled", havingValue = "true")
public class EventPublisher {
    // Service degrades gracefully khi Kafka unavailable
}
```

#### **Retry with Exponential Backoff** (WebSocket reconnect)
```javascript
const RECONNECT_DELAY = 2000; // Start with 2s
// Can be extended: 2s â†’ 4s â†’ 8s â†’ 16s (max 32s)
```

#### **Timeout Pattern**
```java
@Value("${stream.recovery-timeout-minutes:5}")
private int recoveryTimeoutMinutes;

// Streams expire after timeout
streamCache.markComplete(messageId, Duration.ofMinutes(5));
```

#### **Bulkhead Pattern** (Resource isolation)
```yaml
spring:
  data:
    redis:
      lettuce:
        pool:
          max-active: 8   # Limit connections
          max-idle: 4
          min-idle: 2
```

---

### 5. Caching Patterns

#### **Hierarchical Cache (L1 + L2)**

```
Request â†’ L1 Cache (Caffeine - Local, Fast)
             â”‚ MISS
             â–¼
          L2 Cache (Redis - Distributed, Shared)
             â”‚ MISS
             â–¼
          Database (H2 - Persistent)
```

**Benefits:**
- Fast reads from L1 (in-memory, local)
- Shared state in L2 (cross-node consistency)
- Persistent storage in DB (durability)

#### **Cache-Aside Pattern**
```java
public Message getMessage(String messageId) {
    // Try L1
    Message cached = l1Cache.get(messageId);
    if (cached != null) return cached;
    
    // Try L2
    cached = l2Cache.get(messageId);
    if (cached != null) {
        l1Cache.put(messageId, cached);
        return cached;
    }
    
    // Load from DB
    Message message = repository.findById(messageId);
    l2Cache.put(messageId, message);
    l1Cache.put(messageId, message);
    return message;
}
```

#### **Write-Through Cache**
```java
public void saveMessage(Message message) {
    // Write to DB
    repository.save(message);
    
    // Update caches
    l2Cache.put(message.getId(), message);
    l1Cache.put(message.getId(), message);
}
```

---

### 6. Messaging Patterns

#### **Publish-Subscribe** (Redis PubSub)
```
One Publisher (Python AI) â†’ Many Subscribers (Java Nodes)
Fan-out messaging
```

#### **Point-to-Point** (Session Ownership)
```redis
# Only one node handles a session
SET session:owner:{session_id} {node_id} NX EX 600
```

#### **Message Filtering** (Subscribe only to relevant channels)
```java
// Each node subscribes only to its sessions
String channel = "chat:stream:" + sessionId;
listenerContainer.addMessageListener(listener, new ChannelTopic(channel));
```

---

### 7. Data Consistency Patterns

#### **Eventual Consistency**
- Redis PubSub messages may arrive out of order
- Use sequence numbers (chunk index) Ä‘á»ƒ reorder
- Final state eventually consistent

#### **Optimistic Locking** (Session ownership)
```redis
# SETNX returns false if key exists
SET session:owner:{session_id} {node_id} NX

# Only proceed if lock acquired
if (claimed) {
    processSession();
}
```

#### **Idempotency**
```java
// Message processing is idempotent
// Processing same chunk multiple times = same result
if (chunkExists(messageId, index)) {
    log.info("Chunk already processed, skipping");
    return;
}
```

---

### 8. Monitoring & Observability Patterns

#### **Metrics Collection** (MetricsService)
```java
[METRIC] websocket.connection.established
[METRIC] message.streaming.started
[METRIC] message.streaming.completed | duration=2134ms | chunks=42
[METRIC] cache.hit | type=L1
[METRIC] cache.miss | type=L2
[METRIC] error | type=TRANSPORT_ERROR
```

#### **Structured Logging**
```
timestamp [node_id] [thread] LEVEL logger - message
2024-01-01 10:00:00 [ws-node-1] [http-nio-1] INFO ChatOrchestrator - Started streaming session: sessionId=xxx
```

#### **Health Checks**
```yaml
# Actuator endpoints
GET /actuator/health
{
  "status": "UP",
  "components": {
    "redis": { "status": "UP" },
    "kafka": { "status": "UP" },
    "diskSpace": { "status": "UP" }
  }
}
```

#### **Distributed Tracing** (Prepare for future)
```java
// Add trace_id, span_id to logs
log.info("traceId={}, spanId={}, Processing message", traceId, spanId);
```

---

## ğŸš€ Deployment Architecture

### Single-Node Mode (Development)

**File:** `docker-compose.yml`

**Services:**
- 1x Java WebSocket Server (8080)
- 1x Python AI Service (8000)
- 1x Redis (6379)
- 1x Kafka (9092, 9093)
- 1x Frontend (3000)

**Use Case:**
- Development vÃ  testing
- Demo purposes
- Resource-constrained environments

**Start Command:**
```bash
docker-compose up --build
```

---

### Multi-Node Mode (Production)

**File:** `docker-compose.multi-node.yml`

**Services:**
- **3x Java WebSocket Servers** (8081, 8082, 8083)
- **3x Python AI Services** (8001, 8002, 8003)
- **1x NGINX Load Balancer** (8080)
- **1x Redis** (6379) - Shared
- **1x Kafka** (9092, 9093) - Shared
- **1x Frontend** (3000)

**Architecture:**

```
                    Internet
                        â”‚
                        â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Frontend â”‚
                  â”‚ :3000    â”‚
                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  NGINX   â”‚
                  â”‚  :8080   â”‚ Load Balancer
                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼              â–¼              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Java WS1â”‚    â”‚Java WS2â”‚    â”‚Java WS3â”‚
   â”‚  :8081 â”‚    â”‚  :8082 â”‚    â”‚  :8083 â”‚
   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚             â”‚             â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼            â–¼            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Python  â”‚  â”‚Python  â”‚  â”‚Python  â”‚
   â”‚AI #1   â”‚  â”‚AI #2   â”‚  â”‚AI #3   â”‚
   â”‚:8001   â”‚  â”‚:8002   â”‚  â”‚:8003   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â”‚            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼            â–¼            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Redis (Shared)     Kafka       â”‚
   â”‚  :6379              :9092       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Load Balancing Strategy:**

1. **NGINX â†’ Java WebSocket**
   - Algorithm: `ip_hash` (sticky sessions)
   - Reason: Maintain WebSocket connection consistency
   - Health checks every 10s

2. **Java â†’ Python AI**
   - Algorithm: Round-robin (via client-side)
   - Reason: Stateless AI processing
   - Failover: Retry on next node

**Start Command:**
```bash
docker-compose -f docker-compose.multi-node.yml up --build
```

**With Kafka UI (Debug):**
```bash
docker-compose -f docker-compose.multi-node.yml --profile debug up
```

---

### Environment Variables

**Java WebSocket Server:**
```yaml
# Redis
SPRING_DATA_REDIS_HOST: redis
SPRING_DATA_REDIS_PORT: 6379

# Kafka
SPRING_KAFKA_ENABLED: true
SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka:9092

# AI Service
AI_SERVICE_URL: http://nginx-lb:80/ai  # Load-balanced

# Security
JWT_SECRET: your-secret-key
JWT_EXPIRATION_MS: 3600000

# Cache
CACHE_L1_MAX_SIZE: 500
CACHE_L1_EXPIRE_WRITE: 2
CACHE_L2_TTL: 5

# Stream
STREAM_MAX_PENDING_CHUNKS: 1000
STREAM_BACKPRESSURE_DELAY: 10

# Logging
LOG_LEVEL: INFO
NODE_ID: ws-node-1

# JVM
JAVA_OPTS: -Xms512m -Xmx1024m -XX:+UseG1GC
```

**Python AI Service:**
```yaml
# Redis
REDIS_HOST: redis
REDIS_PORT: 6379

# Node identification
NODE_ID: ai-node-1

# Logging
LOG_LEVEL: INFO
```

**Frontend:**
```yaml
# WebSocket (through NGINX)
VITE_WS_URL: ws://localhost:8080/ws/chat

# API (through NGINX)
VITE_API_URL: http://localhost:8080/api
```

---

## ğŸ“ˆ Performance & Scalability

### Performance Metrics

**Latency:**
- WebSocket connection: ~10-20ms
- First chunk delivery: ~50-100ms
- Chunk-to-chunk: ~50ms (configurable)
- History loading: ~50-100ms (depends on size)

**Throughput:**
- Messages per second: ~100-500 (per node)
- Concurrent users: ~1000-5000 (per node)
- Concurrent sessions: ~10,000+ (with proper Redis tuning)

**Resource Usage (per node):**
- Java Backend: 512MB-1GB RAM, 1-2 CPU cores
- Python AI: 256MB-512MB RAM, 1 CPU core
- Redis: 256MB-1GB RAM (depends on history size)
- Kafka: 512MB-2GB RAM

---

### Scalability Strategies

#### **Horizontal Scaling**

**Add more Java nodes:**
```yaml
java-websocket-4:
  # Same config as node 1-3
  ports:
    - "8084:8080"
  environment:
    - NODE_ID=ws-node-4
```

**Add to NGINX upstream:**
```nginx
upstream websocket_backend {
    ip_hash;
    server java-websocket-1:8080;
    server java-websocket-2:8080;
    server java-websocket-3:8080;
    server java-websocket-4:8080;  # New node
}
```

**Benefits:**
- Linear scalability
- No code changes needed
- Auto load-balancing

---

#### **Redis Scaling**

**Current:** Single Redis instance

**Future:** Redis Cluster
```yaml
redis-cluster:
  image: redis:7-alpine
  command: redis-server --cluster-enabled yes
  # 3 master + 3 replica nodes
```

**Benefits:**
- Sharding for large datasets
- High availability (replica failover)
- Horizontal scalability

---

#### **Kafka Scaling**

**Current:** Single Kafka broker (KRaft mode)

**Future:** Kafka cluster
```yaml
kafka-1:
  environment:
    KAFKA_NODE_ID: 1
    KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093

kafka-2:
  environment:
    KAFKA_NODE_ID: 2
    
kafka-3:
  environment:
    KAFKA_NODE_ID: 3
```

**Benefits:**
- Partition distribution
- Replication (fault tolerance)
- Higher throughput

---

### Performance Optimization Tips

**1. Connection Pooling**
```yaml
spring:
  data:
    redis:
      lettuce:
        pool:
          max-active: 20    # Increase for high load
          max-idle: 10
          min-idle: 5
```

**2. Cache Tuning**
```yaml
cache:
  caffeine:
    max-size: 10000         # Increase L1 cache size
    expire-after-write-minutes: 5
```

**3. Chunk Size Optimization**
```python
STREAM_DELAY = 0.03  # 30ms between words (faster)
CHUNK_DELAY = 0.005  # 5ms between chunks
```

**4. Message Batching** (Future)
```java
// Batch multiple chunks into one WebSocket message
List<StreamChunk> batch = new ArrayList<>();
// ... collect chunks ...
sendBatch(wsSession, batch);
```

**5. Compression** (Future)
```nginx
# NGINX gzip compression
gzip on;
gzip_types text/plain application/json;
gzip_min_length 1000;
```

---

## ğŸ”’ Security Considerations

### Current Implementation (PoC)

**JWT Authentication:**
- Token validation on WebSocket connect
- Token passed via query params (dev mode)
- Configurable secret vÃ  expiration

**Development Mode:**
```java
// Allow connections without token
if (token == null) {
    log.warn("No token provided, using development mode");
    return "dev-token";
}
```

---

### Production Recommendations

**1. HTTPS/WSS:**
```nginx
server {
    listen 443 ssl;
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    
    location /ws/ {
        proxy_pass http://websocket_backend;
        # ... WebSocket config ...
    }
}
```

**2. Token in Headers (not query params):**
```javascript
// Bad: Token in URL (visible in logs)
ws://localhost:8080/ws/chat?token=xxx

// Good: Token in headers
const ws = new WebSocket('wss://localhost:8080/ws/chat');
ws.onopen = () => {
    ws.send(JSON.stringify({
        type: 'auth',
        token: 'jwt-token'
    }));
};
```

**3. Rate Limiting:**
```java
@Service
public class RateLimitService {
    private final LoadingCache<String, AtomicInteger> requestCounts;
    
    public boolean allowRequest(String userId) {
        // Limit to 100 requests per minute
        AtomicInteger count = requestCounts.get(userId);
        return count.incrementAndGet() <= 100;
    }
}
```

**4. Input Validation:**
```java
@Valid
public class ChatRequest {
    @NotBlank
    @Size(min = 1, max = 36)
    private String sessionId;
    
    @NotBlank
    @Size(min = 1, max = 5000)
    private String message;
}
```

**5. CORS Configuration:**
```java
@Configuration
public class WebSecurityConfig {
    @Bean
    public CorsFilter corsFilter() {
        CorsConfiguration config = new CorsConfiguration();
        config.setAllowedOrigins(Arrays.asList("https://yourdomain.com"));
        config.setAllowedMethods(Arrays.asList("GET", "POST", "DELETE"));
        // ...
    }
}
```

---

## ğŸ§ª Testing & Quality Assurance

### Testing Strategy (Future)

**Unit Tests:**
```java
@Test
public void testStreamChunkCreation() {
    StreamChunk chunk = StreamChunk.builder()
        .messageId("test-id")
        .index(0)
        .content("Hello")
        .build();
    
    assertEquals("Hello", chunk.getContent());
}
```

**Integration Tests:**
```java
@SpringBootTest
@AutoConfigureWebTestClient
public class ChatIntegrationTest {
    @Test
    public void testChatFlow() {
        // 1. Connect WebSocket
        // 2. Send message
        // 3. Verify streaming response
        // 4. Check history
    }
}
```

**Load Testing:**
```bash
# Using k6 or Apache JMeter
k6 run --vus 100 --duration 60s load-test.js
```

---

## ğŸ“š Lessons Learned & Best Practices

### Do's âœ…

1. **Use Redis PubSub for real-time messaging**
   - Low latency, high throughput
   - Simple pub/sub model
   - Built-in fan-out

2. **Implement hierarchical caching**
   - L1 (local) cho fast access
   - L2 (distributed) cho consistency
   - Automatic invalidation

3. **Use synchronized writes for WebSocket**
   - Prevents TEXT_PARTIAL_WRITING errors
   - Per-session locks
   - Better than global lock

4. **Store state in Redis for distributed systems**
   - Session ownership
   - Cancel flags
   - Active streaming tracking

5. **Check cancellation periodically (not every chunk)**
   - Reduces Redis overhead
   - Max delay acceptable (0.5s)
   - Better performance

6. **Use Kafka for optional features**
   - Event sourcing
   - Analytics
   - Graceful degradation if unavailable

---

### Don'ts âŒ

1. **Don't store large data in Redis PubSub**
   - PubSub khÃ´ng persistent
   - Use for notifications only
   - Store data in Redis Storage or DB

2. **Don't block WebSocket handler thread**
   - Use async processing
   - CompletableFuture cho long operations
   - Keep handler lightweight

3. **Don't forget to cleanup resources**
   - Close WebSocket connections
   - Unsubscribe from PubSub
   - Release distributed locks
   - Delete expired keys

4. **Don't use global locks**
   - Kills concurrency
   - Use per-session or per-resource locks
   - Fine-grained locking

5. **Don't trust client input**
   - Always validate
   - Sanitize messages
   - Rate limiting

---

## ğŸ¯ Future Enhancements

### Phase 2 (Short-term)

1. **Message Editing & Deletion**
   - Edit sent messages
   - Delete messages (soft delete)
   - Sync across all clients

2. **Typing Indicators**
   - Real-time typing status
   - Via Redis PubSub
   - Throttled updates

3. **Read Receipts**
   - Track message read status
   - Store in Redis
   - Update UI

4. **Rich Media Support**
   - Images, files, code blocks
   - Streaming uploads
   - Preview generation

---

### Phase 3 (Medium-term)

1. **Multi-user Conversations**
   - Group chats
   - User presence
   - Message broadcast to multiple users

2. **Search Functionality**
   - Full-text search in history
   - Elasticsearch integration
   - Faceted search

3. **Notification System**
   - Push notifications
   - Email notifications
   - WebSocket fallback

4. **Admin Dashboard**
   - Real-time monitoring
   - User management
   - Analytics dashboard

---

### Phase 4 (Long-term)

1. **AI Model Integration**
   - Replace mock AI with real models
   - OpenAI, Anthropic, local models
   - Model selection per session

2. **Kubernetes Deployment**
   - Auto-scaling
   - Rolling updates
   - Service mesh (Istio)

3. **Advanced Caching**
   - CDN for static assets
   - Edge caching
   - Intelligent prefetching

4. **Machine Learning Features**
   - Response quality scoring
   - Auto-categorization
   - Sentiment analysis

---

## ğŸ“– Káº¿t luáº­n

### Äiá»ƒm máº¡nh cá»§a giáº£i phÃ¡p

1. **Real-time Streaming**
   - âœ… Low latency, high throughput
   - âœ… Scalable architecture
   - âœ… Graceful degradation

2. **Persistence & Recovery**
   - âœ… No data loss on reload
   - âœ… Automatic reconnection
   - âœ… Stream recovery

3. **Distributed System**
   - âœ… Multi-node deployment
   - âœ… Load balancing
   - âœ… Fault tolerance

4. **Developer Experience**
   - âœ… Clean architecture
   - âœ… Well-documented
   - âœ… Easy to extend

---

### Káº¿t quáº£ PoC

**Chá»©ng minh thÃ nh cÃ´ng:**
- âœ… AI streaming chat vá»›i persistent history
- âœ… Real-time communication qua WebSocket
- âœ… Multi-node deployment vá»›i load balancing
- âœ… Distributed state management vá»›i Redis
- âœ… Event sourcing vá»›i Kafka (optional)
- âœ… Auto-recovery vÃ  resilience

**Production-ready:**
- ğŸ”„ Cáº§n thÃªm authentication/authorization
- ğŸ”„ HTTPS/WSS support
- ğŸ”„ Monitoring vÃ  alerting
- ğŸ”„ Comprehensive testing
- ğŸ”„ Performance tuning

---

### TÃ i liá»‡u tham kháº£o

**Technologies:**
- [Spring Boot WebSocket](https://spring.io/guides/gs/messaging-stomp-websocket/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Redis PubSub](https://redis.io/docs/manual/pubsub/)
- [Apache Kafka](https://kafka.apache.org/documentation/)
- [React WebSocket](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)

**Design Patterns:**
- [Microservices Patterns](https://microservices.io/patterns/)
- [Event-Driven Architecture](https://martinfowler.com/articles/201701-event-driven.html)
- [CQRS Pattern](https://martinfowler.com/bliki/CQRS.html)

**Best Practices:**
- [12-Factor App](https://12factor.net/)
- [Cloud Native Patterns](https://www.oreilly.com/library/view/cloud-native-patterns/9781617294297/)

---

**Document Version:** 1.0  
**Last Updated:** 2024-01-01  
**Author:** Development Team  
**Status:** PoC Complete âœ…
